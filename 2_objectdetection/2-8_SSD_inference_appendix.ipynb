{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.8 추론 실시의 부록. 학습 및 검증 DataLoader에 실시\n",
    "\n",
    "학습시킨 SSD로 물체를 감지합니다.\n",
    "\n",
    "\n",
    "VOC2012의 훈련 데이터 세트와 검증 데이터 세트에 대해 학습된 SSD의 추론을 실시하여 추론 결과와 정답 어노테이션 데이터를 모두 표시해 주는 파일입니다.\n",
    "\n",
    "학습시킨 SSD 모델이 올바른 어노테이션 데이터와 얼마나 가까운지 등을 확인하고 싶을 때 활용하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전 준비\n",
    "\n",
    "- \"utils\" 폴더에 2.3～2.7까지 구현한 내용을 정리한 ssd_model.py를 확인하세요\n",
    "- 학습시킨 가중치 파라미터를 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV 라이브러리\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론용 함수와 클래스를 작성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_predict(img_index, img_list, dataset, net=None, dataconfidence_level=0.5):\n",
    "    \"\"\"\n",
    "    SSD로 예측하는 함수\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_index:  int\n",
    "        데이터 세트 내의 예측 대상 화상의 인덱스\n",
    "    img_list: list\n",
    "        화상의 파일 경로 리스트\n",
    "    dataset: PyTorch의 Dataset\n",
    "        화상의 Dataset\n",
    "    net: PyTorch의 Network\n",
    "        학습시킨 SSD 네트워크\n",
    "    dataconfidence_level: float\n",
    "        예측에서 발견했다고 여기는 신뢰도의 임계치\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rgb_img, true_bbox, true_label_index, predict_bbox, pre_dict_label_index, scores\n",
    "    \"\"\"\n",
    "\n",
    "    # rgb의 화상 데이터를 취득\n",
    "    image_file_path = img_list[img_index]\n",
    "    img = cv2.imread(image_file_path)  # [높이][폭][색BGR]\n",
    "    height, width, channels = img.shape  # 화상 크기 취득\n",
    "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 정답 BBox를 취득\n",
    "    im, gt = dataset.__getitem__(img_index)\n",
    "    true_bbox = gt[:, 0:4] * [width, height, width, height]\n",
    "    true_label_index = gt[:, 4].astype(int)\n",
    "\n",
    "    # SSD로 예측\n",
    "    net.eval()  # 네트워크를 추론 모드로\n",
    "    x = im.unsqueeze(0)  # 미니 배치화: torch.Size([1, 3, 300, 300])\n",
    "    detections = net(x)\n",
    "    # detections의 형은, torch.Size([1, 21, 200, 5])  ※200은 top_k의 값\n",
    "\n",
    "    # confidence_level이 기준 이상인 것을 꺼낸다\n",
    "    predict_bbox = []\n",
    "    pre_dict_label_index = []\n",
    "    scores = []\n",
    "    detections = detections.cpu().detach().numpy()\n",
    "\n",
    "    # 조건 이상의 값을 추출\n",
    "    find_index = np.where(detections[:, 0:, :, 0] >= dataconfidence_level)\n",
    "    detections = detections[find_index]\n",
    "    for i in range(len(find_index[1])):  # 추출한 물체수만큼 루프를 돈다\n",
    "        if (find_index[1][i]) > 0:  # 배경 클래스가 아닌 것\n",
    "            sc = detections[i][0]  # 신뢰도\n",
    "            bbox = detections[i][1:] * [width, height, width, height]\n",
    "            lable_ind = find_index[1][i]-1  # find_index는 미니 배치 수, 클래스, top의 tuple\n",
    "            # (주석)\n",
    "            # 배경 클래스는 0이므로 1을 뺀다\n",
    "\n",
    "            # 반환값 리스트에 추가\n",
    "            predict_bbox.append(bbox)\n",
    "            pre_dict_label_index.append(lable_ind)\n",
    "            scores.append(sc)\n",
    "\n",
    "    return rgb_img, true_bbox, true_label_index, predict_bbox, pre_dict_label_index, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_bbox(rgb_img, bbox, label_index, scores, label_names):\n",
    "    \"\"\"\n",
    "    물체 감지의 예측 결과를 화상으로 표시하는 함수.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb_img:rgb의 화상\n",
    "        대상 화상 데이터\n",
    "    bbox: list\n",
    "        물체의 BBox 리스트\n",
    "    label_index: list\n",
    "        물체의 라벨 인덱스\n",
    "    scores: list\n",
    "        물체의 신뢰도\n",
    "    label_names: list\n",
    "        라벨명의 배열\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    없음. rgb_img에 물체 검출 결과가 더해진 화상이 표시된다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 테두리 색상 설정\n",
    "    num_classes = len(label_names)  # 클래스 수(배경 제외)\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, num_classes)).tolist()\n",
    "\n",
    "    # 화상 표시\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(rgb_img)\n",
    "    currentAxis = plt.gca()\n",
    "\n",
    "    # BBox만큼 루프\n",
    "    for i, bb in enumerate(bbox):\n",
    "\n",
    "        # 라벨명\n",
    "        label_name = label_names[label_index[i]]\n",
    "        color = colors[label_index[i]]  # 클래스마다 다른 색깔의 테두리를 부여\n",
    "\n",
    "        # 테두리에 붙이는 라벨 (예: person: 0.72)\n",
    "        if scores is not None:\n",
    "            sc = scores[i]\n",
    "            display_txt = '%s: %.2f' % (label_name, sc)\n",
    "        else:\n",
    "            display_txt = '%s: ans' % (label_name)\n",
    "\n",
    "        # 테두리의 좌표\n",
    "        xy = (bb[0], bb[1])\n",
    "        width = bb[2] - bb[0]\n",
    "        height = bb[3] - bb[1]\n",
    "\n",
    "        # 직사각형 그리기\n",
    "        currentAxis.add_patch(plt.Rectangle(\n",
    "            xy, width, height, fill=False, edgecolor=color, linewidth=2))\n",
    "\n",
    "        # 직사각형의 테두리의 좌측 상단에 라벨을 그린다\n",
    "        currentAxis.text(xy[0], xy[1], display_txt, bbox={\n",
    "                         'facecolor': color, 'alpha': 0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSDPredictShow():\n",
    "    \"\"\"SSD의 예측과 화상의 표시를 한 번에 수행하는 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, img_list, dataset,  eval_categories, net=None, dataconfidence_level=0.6):\n",
    "        self.img_list = img_list\n",
    "        self.dataset = dataset\n",
    "        self.net = net\n",
    "        self.dataconfidence_level = dataconfidence_level\n",
    "        self.eval_categories = eval_categories\n",
    "\n",
    "    def show(self, img_index, predict_or_ans):\n",
    "        \"\"\"\n",
    "        물체 감지의 예측 결과를 표시하는 함수.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img_index:  int\n",
    "            데이터 세트 내의 예측 대상 화상의 인덱스.\n",
    "        predict_or_ans: text\n",
    "            'precit', 'ans'에서, BBox의 예측과 정답 중 어느 것을 표시할지 지정\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        없음. rgb_img에 물체 검출 결과가 더해진 화상이 표시된다.\n",
    "        \"\"\"\n",
    "        rgb_img, true_bbox, true_label_index, predict_bbox, pre_dict_label_index, scores = ssd_predict(img_index, self.img_list,\n",
    "                                                                 self.dataset,\n",
    "                                                                 self.net,\n",
    "                                                                 self.dataconfidence_level)\n",
    "\n",
    "        if predict_or_ans == \"predict\":\n",
    "            vis_bbox(rgb_img, bbox=predict_bbox, label_index=pre_dict_label_index,\n",
    "                     scores=scores, label_names=self.eval_categories)\n",
    "\n",
    "        elif predict_or_ans == \"ans\":\n",
    "            vis_bbox(rgb_img, bbox=true_bbox, label_index=true_label_index,\n",
    "                     scores=None, label_names=self.eval_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론을 실행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n",
    "\n",
    "\n",
    "# 파일 경로 리스트를 취득\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath)\n",
    "\n",
    "# Dataset을 작성\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "color_mean = (104, 117, 123)  # (BGR)의 색 평균값\n",
    "input_size = 300  # 화상의 input 크기를 300×300로 한다\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import SSD\n",
    "\n",
    "# SSD300の設定\n",
    "ssd_cfg = {\n",
    "    'num_classes': 21,  # 배경 클래스를 포함한 총 클래스 수\n",
    "    'input_size': 300,  # 화상의 입력 크기\n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 출력할 Box 화면비의 종류\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 각 source의 화상 크기\n",
    "    'steps': [8, 16, 32, 64, 100, 300],  # DBOX의 크기를 정한다\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOX의 크기를 정한다\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOX의 크기를 정한다\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "# SSD 네트워크 모델\n",
    "net = SSD(phase=\"inference\", cfg=ssd_cfg)\n",
    "net.eval()\n",
    "\n",
    "# SSD의 학습된 가중치를 설정\n",
    "net_weights = torch.load('./weights/ssd300_50.pth',\n",
    "                         map_location={'cuda:0': 'cpu'})\n",
    "\n",
    "#net_weights = torch.load('./weights/ssd300_mAP_77.43_v2.pth',\n",
    "#                         map_location={'cuda:0': 'cpu'})\n",
    "\n",
    "net.load_state_dict(net_weights)\n",
    "\n",
    "# GPU를 사용할 수 있는지 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"사용 중인 장치:\", device)\n",
    "\n",
    "print('네트워크 설정 완료: 학습된 가중치를 로드했습니다')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 그리기\n",
    "ssd = SSDPredictShow(img_list=train_img_list, dataset=train_dataset, eval_categories=voc_classes,\n",
    "                     net=net, dataconfidence_level=0.6)\n",
    "img_index = 0\n",
    "ssd.show(img_index, \"predict\")\n",
    "ssd.show(img_index, \"ans\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 그리기\n",
    "ssd = SSDPredictShow(img_list=val_img_list, dataset=val_dataset, eval_categories=voc_classes,\n",
    "                     net=net, dataconfidence_level=0.6)\n",
    "img_index = 0\n",
    "ssd.show(img_index, \"predict\")\n",
    "ssd.show(img_index, \"ans\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "끝"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}