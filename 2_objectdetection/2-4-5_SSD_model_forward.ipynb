{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F94O4yYxGw8M"
      },
      "source": [
        "# 2.4 네트워크 모델의 구현, 2.5 순전파 함수의 구현\n",
        "\n",
        "SSD의 네트워크 모델과 순전파(forward) 함수를 작성합니다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JPc7kqyjGw8Q"
      },
      "source": [
        "# 2.4 학습 목표\n",
        "\n",
        "1. SSD의 네트워크 모델을 구축하는 4개의 모듈을 파악한다\n",
        "2. SSD의 네트워크 모델을 만들 수 있다\n",
        "3. SSD에서 사용하는 다양한 크기의 디폴트 박스의 구현 방법을 이해한다\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lcaeSHrlGw8S"
      },
      "source": [
        "# 2.5 학습 목표\n",
        "\n",
        "1. Non-Maximum Suppression을 이해한다\n",
        "2. SSD의 추론시 사용하는 Detect 클래스의 순전파를 이해한다\n",
        "3. SSD 순전파를 구현할 수 있다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eP5qFbGsGw8T"
      },
      "source": [
        "# 사전 준비\n",
        "\n",
        "\n",
        "없음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5SezJNFsGw8U"
      },
      "outputs": [],
      "source": [
        "# 패키지 import\n",
        "from math import sqrt\n",
        "from itertools import product\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_dzZn2Y3Gw8a"
      },
      "source": [
        "# vgg 모듈 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "seziJ76uGw8b",
        "outputId": "a23d228c-e2fb-469b-c3b5-88ea6e5fb5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): ReLU(inplace=True)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): ReLU(inplace=True)\n",
            "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU(inplace=True)\n",
            "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): ReLU(inplace=True)\n",
            "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (20): ReLU(inplace=True)\n",
            "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (22): ReLU(inplace=True)\n",
            "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (25): ReLU(inplace=True)\n",
            "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (27): ReLU(inplace=True)\n",
            "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (29): ReLU(inplace=True)\n",
            "  (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "  (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "  (32): ReLU(inplace=True)\n",
            "  (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (34): ReLU(inplace=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 34층에 걸쳐, vgg모듈을 작성\n",
        "def make_vgg():\n",
        "    layers = []\n",
        "    in_channels = 3  # 색 채널 수 \n",
        "\n",
        "    # vgg 모듈에서 사용하는 합성곱 층이나 맥스 풀링의 채널 수\n",
        "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256,\n",
        "           256, 'MC', 512, 512, 512, 'M', 512, 512, 512]\n",
        "\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        elif v == 'MC':\n",
        "            # ceil은 출력 크기를 계산 결과(float)에 대해, 소수점을 올려 정수로 하는 모드\n",
        "            # 디폴트는 출력 크기를 계산 결과(float)에 대해, 소수점을 버려 정수로 하는 floor 모드\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "\n",
        "    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "    conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)\n",
        "    conv7 = nn.Conv2d(1024, 1024, kernel_size=1)\n",
        "    layers += [pool5, conv6,\n",
        "               nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]\n",
        "    return nn.ModuleList(layers)\n",
        "\n",
        "\n",
        "# 동작 확인\n",
        "vgg_test = make_vgg()\n",
        "print(vgg_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9T7XgWrKGw8g"
      },
      "source": [
        "# extras 모듈 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2i04NYMoGw8h",
        "outputId": "af5cf9cd-4011-4d63-fab5-7ba4eed77075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModuleList(\n",
            "  (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 8층에 걸친 extras모듈 작성\n",
        "def make_extras():\n",
        "    layers = []\n",
        "    in_channels = 1024  # vgg모듈에서 출력된, extra에 입력되는 화상 채널 수\n",
        "\n",
        "    # extra모듈의 합성곱층의 채널수를 설정하는 구성(configuration)\n",
        "    cfg = [256, 512, 128, 256, 128, 256, 128, 256]\n",
        "\n",
        "    layers += [nn.Conv2d(in_channels, cfg[0], kernel_size=(1))]\n",
        "    layers += [nn.Conv2d(cfg[0], cfg[1], kernel_size=(3), stride=2, padding=1)]\n",
        "    layers += [nn.Conv2d(cfg[1], cfg[2], kernel_size=(1))]\n",
        "    layers += [nn.Conv2d(cfg[2], cfg[3], kernel_size=(3), stride=2, padding=1)]\n",
        "    layers += [nn.Conv2d(cfg[3], cfg[4], kernel_size=(1))]\n",
        "    layers += [nn.Conv2d(cfg[4], cfg[5], kernel_size=(3))]\n",
        "    layers += [nn.Conv2d(cfg[5], cfg[6], kernel_size=(1))]\n",
        "    layers += [nn.Conv2d(cfg[6], cfg[7], kernel_size=(3))]\n",
        "    \n",
        "    # 활성화 함수의 ReLU는 이번에는 SSD모듈의 순전파 속에서 준비하는 것으로 하고,\n",
        "    # extra모듈에서는 준비하지 않음\n",
        "\n",
        "    return nn.ModuleList(layers)\n",
        "\n",
        "# 동작 확인\n",
        "extras_test = make_extras()\n",
        "print(extras_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lpMwWQfZGw8m"
      },
      "source": [
        "# loc 및 conf 모듈 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-vXKr2WnGw8o",
        "outputId": "f085d3ef-d4ea-48ff-cca0-c67aeafa8b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModuleList(\n",
            "  (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            ")\n",
            "ModuleList(\n",
            "  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4-5): 2 x Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 디폴트 박스의 오프셋을 출력하는 loc_layers,\n",
        "# 디폴트 박스에 대한 각 클래스의 신뢰도 confidence를 출력하는 conf_layers를 작성\n",
        "def make_loc_conf(num_classes=21, bbox_aspect_num=[4, 6, 6, 6, 4, 4]):\n",
        "\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "\n",
        "    # VGG의 22층, conv4_3(source1)에 대한 합성곱층\n",
        "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[0]\n",
        "                             * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[0]\n",
        "                              * num_classes, kernel_size=3, padding=1)]\n",
        "\n",
        "    # VGG의 최종층(source2)에 대한 합성곱층\n",
        "    loc_layers += [nn.Conv2d(1024, bbox_aspect_num[1]\n",
        "                             * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(1024, bbox_aspect_num[1]\n",
        "                              * num_classes, kernel_size=3, padding=1)]\n",
        "\n",
        "    # extra(source3)에 대한 합성곱층\n",
        "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[2]\n",
        "                             * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[2]\n",
        "                              * num_classes, kernel_size=3, padding=1)]\n",
        "\n",
        "    # extra(source4)에 대한 합성곱층\n",
        "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[3]\n",
        "                             * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[3]\n",
        "                              * num_classes, kernel_size=3, padding=1)]\n",
        "\n",
        "    # extra(source5)에 대한 합성곱층\n",
        "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[4]\n",
        "                             * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[4]\n",
        "                              * num_classes, kernel_size=3, padding=1)]\n",
        "\n",
        "    # extra(source6)에 대한 합성곱층\n",
        "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[5]\n",
        "                             * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[5]\n",
        "                              * num_classes, kernel_size=3, padding=1)]\n",
        "\n",
        "    return nn.ModuleList(loc_layers), nn.ModuleList(conf_layers)\n",
        "\n",
        "\n",
        "# 동작 확인\n",
        "loc_test, conf_test = make_loc_conf()\n",
        "print(loc_test)\n",
        "print(conf_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tOgBNY7FGw8s"
      },
      "source": [
        "# L2Norm 층 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8EwzMY9fGw8u"
      },
      "outputs": [],
      "source": [
        "# convC4_3로부터의 출력을 scale=20의 L2Norm으로 정규화하는 층\n",
        "class L2Norm(nn.Module):\n",
        "    def __init__(self, input_channels=512, scale=20):\n",
        "        super(L2Norm, self).__init__()  # 부모 클래스의 생성자 실행\n",
        "        self.weight = nn.Parameter(torch.Tensor(input_channels))\n",
        "        self.scale = scale  # 계수 weight의 초기값으로 설정할 값\n",
        "        self.reset_parameters()  # 파라미터의 초기화\n",
        "        self.eps = 1e-10\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        '''결합 파라미터의 scale크기 값으로 초기화 실행'''\n",
        "        init.constant_(self.weight, self.scale)  # weight의 값이 모두 scale(=20)이 된다\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''38×38의 특징량에 대해 512 채널에 걸쳐 제곱합의 루트를 구했다\n",
        "        38×38개의 값을 사용하여 각 특징량을 정규화한 후 계수를 곱하여 계산하는 층'''\n",
        "\n",
        "        # 각 채널에서의 38×38개의 특징량의 채널 방향의 제곱합을 계산하고,\n",
        "        # 또한 루트를 구해 나누어 정규화한다\n",
        "        # norm의 텐서 사이즈는 torch.Size([batch_num, 1, 38, 38])입니다\n",
        "        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt()+self.eps\n",
        "        x = torch.div(x, norm)\n",
        "\n",
        "        # 계수를 곱한다. 계수는 채널마다 하나로, 512개의 계수를 갖는다\n",
        "        # self.weight의 텐서 사이즈는 torch.Size([512])이므로\n",
        "        # torch.Size([batch_num, 512, 38, 38])까지 변형합니다\n",
        "        weights = self.weight.unsqueeze(\n",
        "            0).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
        "        out = weights * x\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0zN8JIPvGw8x"
      },
      "source": [
        "# 디폴트 박스 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Q6K7TmuLGw8z"
      },
      "outputs": [],
      "source": [
        "# 디폴트 박스를 출력하는 클래스\n",
        "class DBox(object):\n",
        "    def __init__(self, cfg):\n",
        "        super(DBox, self).__init__()\n",
        "\n",
        "        # 초기설정\n",
        "        self.image_size = cfg['input_size']  # 화상 크기 300\n",
        "        # [38, 19, …] 각 source의 특징량 맵의 크기\n",
        "        self.feature_maps = cfg['feature_maps']\n",
        "        self.num_priors = len(cfg[\"feature_maps\"])  # source의 개수 6\n",
        "        self.steps = cfg['steps']  # [8, 16, …] DBox의 픽셀 크기\n",
        "        \n",
        "        self.min_sizes = cfg['min_sizes']\n",
        "        # [30, 60, …] 작은 정사각형의 DBox 픽셀 크기(정확히는 면적)\n",
        "        \n",
        "        self.max_sizes = cfg['max_sizes']\n",
        "        # [60, 111, …] 큰 정사각형의 DBox 픽셀 크기(정확히는 면적)\n",
        "        \n",
        "        self.aspect_ratios = cfg['aspect_ratios']  # 정사각형의 DBox의 화면비(종횡비)\n",
        "\n",
        "    def make_dbox_list(self):\n",
        "        '''DBox를 작성한다'''\n",
        "        mean = []\n",
        "        # 'feature_maps': [38, 19, 10, 5, 3, 1]\n",
        "        for k, f in enumerate(self.feature_maps):\n",
        "            for i, j in product(range(f), repeat=2):  # f까지의 수로 두 쌍의 조합을 작성한다 f_P_2개\n",
        "                # 특징량의 화상 크기\n",
        "                # 300 / 'steps': [8, 16, 32, 64, 100, 300],\n",
        "                f_k = self.image_size / self.steps[k]\n",
        "\n",
        "                # DBox의 중심 좌표 x,y. 0~1로 정규화되어 있음\n",
        "                cx = (j + 0.5) / f_k\n",
        "                cy = (i + 0.5) / f_k\n",
        "\n",
        "                # 화면비 1의 작은 DBox [cx,cy, width, height]\n",
        "                # 'min_sizes': [30, 60, 111, 162, 213, 264]\n",
        "                s_k = self.min_sizes[k]/self.image_size\n",
        "                mean += [cx, cy, s_k, s_k]\n",
        "\n",
        "                # 화면비 1의 큰 DBox [cx,cy, width, height]\n",
        "                # 'max_sizes': [60, 111, 162, 213, 264, 315],\n",
        "                s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size))\n",
        "                mean += [cx, cy, s_k_prime, s_k_prime]\n",
        "\n",
        "                # 그 외 화면비의 defBox [cx,cy, width, height]\n",
        "                for ar in self.aspect_ratios[k]:\n",
        "                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]\n",
        "                    mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]\n",
        "\n",
        "        # DBox를 텐서로 변환 torch.Size([8732, 4])\n",
        "        output = torch.Tensor(mean).view(-1, 4)\n",
        "\n",
        "        # DBox가 화상 밖으로 돌출되는 것을 막기 위해, 크기를 최소 0, 최대 1로 한다\n",
        "        output.clamp_(max=1, min=0)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rMQnyO-VGw83",
        "outputId": "48ff0468-4eac-4d33-ae90-92ffb86fa8a4"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m dbox_list \u001b[38;5;241m=\u001b[39m dbox\u001b[38;5;241m.\u001b[39mmake_dbox_list()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# DBox 출력을 확인한다\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mdbox_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ],
      "source": [
        "# 동작 확인\n",
        "\n",
        "# SSD300 설정\n",
        "ssd_cfg = {\n",
        "    'num_classes': 21,  # 배경 클래스를 포함한 총 클래스 수\n",
        "    'input_size': 300,  # 화상의 입력 크기\n",
        "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 출력할 Box 화면비의 종류\n",
        "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 각 source의 화상 크기\n",
        "    'steps': [8, 16, 32, 64, 100, 300],  # DBOX의 크기를 정한다\n",
        "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOX의 크기를 정한다\n",
        "    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOX의 크기를 정한다\n",
        "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
        "}\n",
        "\n",
        "# DBox 작성\n",
        "dbox = DBox(ssd_cfg)\n",
        "dbox_list = dbox.make_dbox_list()\n",
        "\n",
        "# DBox 출력을 확인한다\n",
        "pd.DataFrame(dbox_list.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WNgaY_bUGw87"
      },
      "source": [
        "# SSD 클래스 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "soAjguIYGw89",
        "outputId": "10c682f5-84d2-4646-eb90-88fc739a6495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SSD(\n",
            "  (vgg): ModuleList(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace)\n",
            "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "    (32): ReLU(inplace)\n",
            "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (34): ReLU(inplace)\n",
            "  )\n",
            "  (extras): ModuleList(\n",
            "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "  )\n",
            "  (L2Norm): L2Norm()\n",
            "  (loc): ModuleList(\n",
            "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (conf): ModuleList(\n",
            "    (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# SSD 클래스를 작성한다\n",
        "class SSD(nn.Module):\n",
        "\n",
        "    def __init__(self, phase, cfg):\n",
        "        super(SSD, self).__init__()\n",
        "\n",
        "        self.phase = phase  # train or inference를 지정\n",
        "        self.num_classes = cfg[\"num_classes\"]  # 클래스 수 21\n",
        "\n",
        "        # SSD 네트워크를 작성\n",
        "        self.vgg = make_vgg()\n",
        "        self.extras = make_extras()\n",
        "        self.L2Norm = L2Norm()\n",
        "        self.loc, self.conf = make_loc_conf(\n",
        "            cfg[\"num_classes\"], cfg[\"bbox_aspect_num\"])\n",
        "\n",
        "        # DBox 작성\n",
        "        dbox = DBox(cfg)\n",
        "        self.dbox_list = dbox.make_dbox_list()\n",
        "\n",
        "        # 추론시는 \"Detect\" 클래스를 준비합니다\n",
        "        if phase == 'inference':\n",
        "            self.detect = Detect()\n",
        "\n",
        "\n",
        "# 동작 확인\n",
        "ssd_test = SSD(phase=\"train\", cfg=ssd_cfg)\n",
        "print(ssd_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e2kmA27KGw9C"
      },
      "source": [
        "# 여기부터 2.5절 순전파의 구현입니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4PiaKi9QGw9E"
      },
      "source": [
        "# decode 함수 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0hL7JLRyGw9F"
      },
      "outputs": [],
      "source": [
        "# 오프셋 정보를 이용하여 DBox를 BBox로 변환하는 함수\n",
        "def decode(loc, dbox_list):\n",
        "    \"\"\"\n",
        "    오프셋 정보를 이용하여 DBox를 BBox로 변환한다.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    loc:  [8732,4]\n",
        "        SSD 모델로 추론하는 오프셋 정보.\n",
        "    dbox_list: [8732,4]\n",
        "        DBox 정보\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    boxes : [xmin, ymin, xmax, ymax]\n",
        "        BBox 정보\n",
        "    \"\"\"\n",
        "\n",
        "    # DBox는 [cx, cy, width, height]로 저장되어 있음\n",
        "    # loc도 [Δcx, Δcy, Δwidth, Δheight]로 저장되어 있음\n",
        "\n",
        "    # 오프셋 정보로 BBox를 구한다\n",
        "    boxes = torch.cat((\n",
        "        dbox_list[:, :2] + loc[:, :2] * 0.1 * dbox_list[:, 2:],\n",
        "        dbox_list[:, 2:] * torch.exp(loc[:, 2:] * 0.2)), dim=1)\n",
        "    # boxes의 크기는 torch.Size([8732, 4])가 됩니다\n",
        "\n",
        "    # BBox의 좌표정보를 [cx, cy, width, height]에서 [xmin, ymin, xmax, ymax]으로 변경\n",
        "    boxes[:, :2] -= boxes[:, 2:] / 2  # 좌표 (xmin,ymin)로 변환\n",
        "    boxes[:, 2:] += boxes[:, :2]  # 좌표 (xmax,ymax)로 변환\n",
        "\n",
        "    return boxes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GRWdh3ZlGw9K"
      },
      "source": [
        "# Non-Maximum Suppression을 실시하는 함수를 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wtndAFgxGw9M"
      },
      "outputs": [],
      "source": [
        "# Non-Maximum Suppression을 실시하는 함수\n",
        "def nm_suppression(boxes, scores, overlap=0.45, top_k=200):\n",
        "    \"\"\"\n",
        "    Non-Maximum Suppression을 실시하는 함수.\n",
        "    boxes 중에서 겹치는(overlap 이상)의 BBox를 삭제한다.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    boxes : [신뢰도 임계값(0.01)을 넘은 BBox 수,4]\n",
        "        BBox 정보\n",
        "    scores :[신뢰도 임계값(0.01)을 넘은 BBox 수]\n",
        "        conf 정보\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    keep : 리스트\n",
        "        conf의 내림차순으로 nms를 통과한 index가 저장됨\n",
        "    count: int\n",
        "        nms를 통과한 BBox 수\n",
        "    \"\"\"\n",
        "\n",
        "    # return의 모형을 작성\n",
        "    count = 0\n",
        "    keep = scores.new(scores.size(0)).zero_().long()\n",
        "    # keep: torch.Size([신뢰도 임계값을 넘은 BBox 수]), 요소는 전부 0\n",
        "\n",
        "    # 각 BBox의 면적 area를 계산\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "    area = torch.mul(x2 - x1, y2 - y1)\n",
        "\n",
        "    # boxes를 복사한다. 나중에 BBox 중복도(IOU) 계산시의 모형으로 준비\n",
        "    tmp_x1 = boxes.new()\n",
        "    tmp_y1 = boxes.new()\n",
        "    tmp_x2 = boxes.new()\n",
        "    tmp_y2 = boxes.new()\n",
        "    tmp_w = boxes.new()\n",
        "    tmp_h = boxes.new()\n",
        "\n",
        "    # socre를 오름차순으로 나열한다\n",
        "    v, idx = scores.sort(0)\n",
        "\n",
        "    # 상위 top_k개(200개)의 BBox의 index를 꺼낸다(200개 존재하지 않는 경우도 있음)\n",
        "    idx = idx[-top_k:]\n",
        "\n",
        "    # idx의 요소수가 0가 아닌 한 루프한다\n",
        "    while idx.numel() > 0:\n",
        "        i = idx[-1]  # conf의 최대 index를 i로\n",
        "\n",
        "        # keep의 끝에 conf 최대 index를 저장\n",
        "        # 이 index의 BBox와 크게 겹치는 BBox를 삭제\n",
        "        keep[count] = i\n",
        "        count += 1\n",
        "\n",
        "        # 마지막 BBox인 경우 루프를 빠져나옴\n",
        "        if idx.size(0) == 1:\n",
        "            break\n",
        "\n",
        "        # 현재 conf 최대의 index를 keep에 저장했으므로, idx를 하나 감소시킴\n",
        "        idx = idx[:-1]\n",
        "\n",
        "        # -------------------\n",
        "        # 이제부터 keep에 저장한 BBox과 크게 겹치는 BBox를 추출하여 삭제한다\n",
        "        # -------------------\n",
        "        # 하나 감소시킨 idx까지의 BBox를, out으로 지정한 변수로 작성한다\n",
        "        torch.index_select(x1, 0, idx, out=tmp_x1)\n",
        "        torch.index_select(y1, 0, idx, out=tmp_y1)\n",
        "        torch.index_select(x2, 0, idx, out=tmp_x2)\n",
        "        torch.index_select(y2, 0, idx, out=tmp_y2)\n",
        "\n",
        "        # 모든 BBox에 대해, 현재 BBox=index가 i로 겹치는 값까지로 설정(clamp)\n",
        "        tmp_x1 = torch.clamp(tmp_x1, min=x1[i])\n",
        "        tmp_y1 = torch.clamp(tmp_y1, min=y1[i])\n",
        "        tmp_x2 = torch.clamp(tmp_x2, max=x2[i])\n",
        "        tmp_y2 = torch.clamp(tmp_y2, max=y2[i])\n",
        "\n",
        "        # w와 h의 텐서 크기를 index를 하나 줄인 것으로 한다\n",
        "        tmp_w.resize_as_(tmp_x2)\n",
        "        tmp_h.resize_as_(tmp_y2)\n",
        "\n",
        "        # clamp한 상태에서 BBox의 폭과 높이를 구한다\n",
        "        tmp_w = tmp_x2 - tmp_x1\n",
        "        tmp_h = tmp_y2 - tmp_y1\n",
        "\n",
        "        # 폭이나 높이가 음수인 것은 0으로 한다\n",
        "        tmp_w = torch.clamp(tmp_w, min=0.0)\n",
        "        tmp_h = torch.clamp(tmp_h, min=0.0)\n",
        "\n",
        "        # clamp된 상태의 면적을 구한다\n",
        "        inter = tmp_w*tmp_h\n",
        "\n",
        "        # IoU = intersect부분 / (area(a) + area(b) - intersect부분)의 계산\n",
        "        rem_areas = torch.index_select(area, 0, idx)  # 각 BBox의 원래 면적\n",
        "        union = (rem_areas - inter) + area[i]  # 두 구역의 합(OR)의 면적\n",
        "        IoU = inter/union\n",
        "\n",
        "        # IoU가 overlap보다 작은 idx만 남긴다\n",
        "        idx = idx[IoU.le(overlap)]  # le은 Less than or Equal to 처리를 하는 연산입니다\n",
        "        # IoU가 overlap보다 큰 idx는 처음 선택한 keep에 저장한 idx과 동일한 물체에 대해 BBox를 둘러싸고 있으므로 삭제\n",
        "\n",
        "    # while 루프에서 빠져나오면 종료\n",
        "\n",
        "    return keep, count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hf1a7f4nGw9S"
      },
      "source": [
        "# Detect 클래스 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LFV7wK4GGw9T"
      },
      "outputs": [],
      "source": [
        "# SSD 추론시에 conf와 loc의 출력에서 겹침(중복)을 제거한 BBox를 출력한다\n",
        "class Detect(Function):\n",
        "\n",
        "    def __init__(self, conf_thresh=0.01, top_k=200, nms_thresh=0.45):\n",
        "        self.softmax = nn.Softmax(dim=-1)  # conf를 소프트맥스 함수로 정규화하기 위해 준비\n",
        "        self.conf_thresh = conf_thresh  # conf가 conf_thresh=0.01보다 높은 DBox만을 취급\n",
        "        self.top_k = top_k  # nm_supression으로 conf가 높은 top_k개의 계산에 사용하는, top_k = 200\n",
        "        self.nms_thresh = nms_thresh  # nm_supression으로 IOU가 nms_thresh=0.45보다 크면 동일한 물체의 BBox로 간주\n",
        "\n",
        "    def forward(self, loc_data, conf_data, dbox_list):\n",
        "        \"\"\"\n",
        "        순전파 계산을 수행한다.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        loc_data:  [batch_num,8732,4]\n",
        "            오프셋 정보\n",
        "        conf_data: [batch_num, 8732,num_classes]\n",
        "            감지 신뢰도\n",
        "        dbox_list: [8732,4]\n",
        "            DBox의 정보\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output : torch.Size([batch_num, 21, 200, 5])\n",
        "            (batch_num, 클래스, conf의 top200, BBox 정보)\n",
        "        \"\"\"\n",
        "\n",
        "        # 각 크기를 취득\n",
        "        num_batch = loc_data.size(0)  # 미니 배치 크기\n",
        "        num_dbox = loc_data.size(1)  # DBox 수 = 8732\n",
        "        num_classes = conf_data.size(2)  # 클래스 수 = 21\n",
        "\n",
        "        # conf는 소프트맥스를 적용하여 정규화한다\n",
        "        conf_data = self.softmax(conf_data)\n",
        "\n",
        "        # 출력 형식을 작성한다. 텐서 크기는 [minibatch수, 21, 200, 5]\n",
        "        output = torch.zeros(num_batch, num_classes, self.top_k, 5)\n",
        "\n",
        "        # cof_data를 [batch_num,8732,num_classes]에서 [batch_num, num_classes,8732]에 순서 변경\n",
        "        conf_preds = conf_data.transpose(2, 1)\n",
        "\n",
        "        # 미니 배치마다 루프\n",
        "        for i in range(num_batch):\n",
        "\n",
        "            # 1. loc와 DBox로 수정한 BBox [xmin, ymin, xmax, ymax] 를 구한다\n",
        "            decoded_boxes = decode(loc_data[i], dbox_list)\n",
        "\n",
        "            # conf의 복사본을 작성\n",
        "            conf_scores = conf_preds[i].clone()\n",
        "\n",
        "            # 화상 클래스별 루프(배경 클래스의 index인 0은 계산하지 않고, index=1부터)\n",
        "            for cl in range(1, num_classes):\n",
        "\n",
        "                # 2.conf의 임계값을 넘은 BBox를 꺼낸다\n",
        "                # conf의 임계값을 넘고 있는지에 대한 마스크를 작성하여,\n",
        "                # 임계값을 넘은 conf의 인덱스를 c_mask로 취득\n",
        "                c_mask = conf_scores[cl].gt(self.conf_thresh)\n",
        "                # gt는 Greater than을 의미. gt에 의해 임계값을 넘은 것이 1, 이하는 0이 된다.\n",
        "                # conf_scores:torch.Size([21, 8732])\n",
        "                # c_mask:torch.Size([8732])\n",
        "\n",
        "                # scores는 torch.Size([임계값을 넘은 BBox 수])\n",
        "                scores = conf_scores[cl][c_mask]\n",
        "\n",
        "                # 임계값을 넘은 conf가 없는 경우, 즉 scores=[]의 경우에는 아무것도 하지 않는다\n",
        "                if scores.nelement() == 0:  # nelement로 요소수의 함계를 구한다\n",
        "                    continue\n",
        "\n",
        "                # c_mask를 decoded_boxes에 적용할 수 있도록 크기를 변경합니다\n",
        "                l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes)\n",
        "                # l_mask:torch.Size([8732, 4])\n",
        "\n",
        "                # l_mask를 decoded_boxes로 적용합니다\n",
        "                boxes = decoded_boxes[l_mask].view(-1, 4)\n",
        "                # decoded_boxes[l_mask]로 1차원이 되어버리기 때문에,\n",
        "                # view에서 (임계값을 넘은 BBox 수, 4) 크기로 변형한다\n",
        "\n",
        "                # 3. Non-Maximum Suppression를 실시하여, 겹치는 BBox를 제거\n",
        "                ids, count = nm_suppression(\n",
        "                    boxes, scores, self.nms_thresh, self.top_k)\n",
        "                # ids: conf의 내림차순으로 Non-Maximum Suppression를 통과한 index가 저장됨\n",
        "                # count: Non-Maximum Suppression를 통과한 BBox 수\n",
        "\n",
        "                # output에 Non-Maximum Suppression를 뺀 결과를 저장\n",
        "                output[i, cl, :count] = torch.cat((scores[ids[:count]].unsqueeze(1),\n",
        "                                                   boxes[ids[:count]]), 1)\n",
        "\n",
        "        return output  # torch.Size([1, 21, 200, 5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MYaeLRx_Gw9Z"
      },
      "source": [
        "# SSD 클래스 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "55Sgd5HBGw9b"
      },
      "outputs": [],
      "source": [
        "# SSD 클래스를 작성한다\n",
        "class SSD(nn.Module):\n",
        "\n",
        "    def __init__(self, phase, cfg):\n",
        "        super(SSD, self).__init__()\n",
        "\n",
        "        self.phase = phase  # train or inference를 지정\n",
        "        self.num_classes = cfg[\"num_classes\"]  # 클래스 수=21\n",
        "\n",
        "        # SSD 네트워크를 만든다\n",
        "        self.vgg = make_vgg()\n",
        "        self.extras = make_extras()\n",
        "        self.L2Norm = L2Norm()\n",
        "        self.loc, self.conf = make_loc_conf(\n",
        "            cfg[\"num_classes\"], cfg[\"bbox_aspect_num\"])\n",
        "\n",
        "        # DBox 작성\n",
        "        dbox = DBox(cfg)\n",
        "        self.dbox_list = dbox.make_dbox_list()\n",
        "\n",
        "        # 추론시에는 \"Detect\" 클래스를 준비합니다\n",
        "        if phase == 'inference':\n",
        "            self.detect = Detect()\n",
        "\n",
        "    def forward(self, x):\n",
        "        sources = list()  # loc와 conf로의 입력 source1-6을 저장\n",
        "        loc = list()  # loc의 출력을 저장\n",
        "        conf = list()  # conf의 출력을 저장\n",
        "\n",
        "        # vgg의 conv4_3까지 계산한다\n",
        "        for k in range(23):\n",
        "            x = self.vgg[k](x)\n",
        "\n",
        "        # conv4_3의 출력을 L2Norm에 입력하고, source1을 작성하여, sources에 추가\n",
        "        source1 = self.L2Norm(x)\n",
        "        sources.append(source1)\n",
        "\n",
        "        # vgg를 끝까지 계산하여, source2를 작성하고, sources에 추가\n",
        "        for k in range(23, len(self.vgg)):\n",
        "            x = self.vgg[k](x)\n",
        "\n",
        "        sources.append(x)\n",
        "\n",
        "        # extras의 conv와 ReLU를 계산\n",
        "        # source3~6을 sources에 추가\n",
        "        for k, v in enumerate(self.extras):\n",
        "            x = F.relu(v(x), inplace=True)\n",
        "            if k % 2 == 1:  # conv→ReLU→cov→ReLU를 하여 source에 넣는다\n",
        "                sources.append(x)\n",
        "\n",
        "        # source1~6에 각각 대응하는 합성곱을 1회씩 적용한다\n",
        "        # zip으로 for 루프의 여러 리스트 요소를 취득\n",
        "        # source1~6까지 있으므로 루프가 6회 실시됨\n",
        "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
        "            # Permute으로 요소의 순서를 교체\n",
        "            loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "            # l(x)와 c(x)으로 합성곱을 실행\n",
        "            # l(x)와 c(x)의 출력 크기는 [batch_num, 4*화면비의 종류 수, featuremap 높이, featuremap 폭]\n",
        "            # source에 따라 화면비의 종류 수가 다르며, 번거로우므로 순서 교체로 조정한다\n",
        "            # permute로 요소 순서를 교체하여,\n",
        "            # [minibatch 수, featuremap 수, featuremap 수, 4*화면비의 종류 수]으로\n",
        "            # (주석)\n",
        "            # torch.contiguous()은 메모리 상에 요소를 연속적으로 배치하는 명령입니다\n",
        "            # 다음으로 view 함수를 사용합니다.\n",
        "            # 이 view를 수행하기 때문에, 대상의 변수가 메모리 상에 연속적으로 배치되어 있어야 합니다.\n",
        "\n",
        "        # 또한 loc와 conf의 형을 변형\n",
        "        # loc의 크기는 torch.Size([batch_num, 34928])\n",
        "        # conf의 크기는 torch.Size([batch_num, 183372])가 된다\n",
        "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
        "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
        "\n",
        "        # 그리고 loc와 conf의 형을 변형\n",
        "        # loc의 크기는 torch.Size([batch_num, 8732, 4])\n",
        "        # conf의 크기는 torch.Size([batch_num, 8732, 21])\n",
        "        loc = loc.view(loc.size(0), -1, 4)\n",
        "        conf = conf.view(conf.size(0), -1, self.num_classes)\n",
        "\n",
        "        # 마지막으로 출력한다\n",
        "        output = (loc, conf, self.dbox_list)\n",
        "\n",
        "        if self.phase == \"inference\":  # 추론시\n",
        "            # \"Detect\" 클래스의 forward를 실행\n",
        "            # 반환값의 크기는 torch.Size([batch_num, 21, 200, 5])\n",
        "            return self.detect(output[0], output[1], output[2])\n",
        "\n",
        "        else:  # 학습시\n",
        "            return output\n",
        "            # 반환값은 (loc, conf, dbox_list)의 튜플\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vLqzjJLEGw9e"
      },
      "source": [
        "끝"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "2-4-5_SSD_model_forward.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
