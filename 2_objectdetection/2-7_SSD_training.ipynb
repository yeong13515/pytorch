{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7 학습 및 검증 실시\n",
    "\n",
    "- SSD 학습과 검증의 실시를 수행합니다. 로컬 머신으로 동작을 확인한 뒤, AWS의 GPU 머신으로 계산합니다.\n",
    "- p2.xlarge에서 약 6시간 걸립니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 목표\n",
    "\n",
    "1.\tSSD 학습을 구현할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전 준비\n",
    "\n",
    "- AWS EC2의 GPU 인스턴스를 사용합니다\n",
    "- \"utils\" 폴더의 ssd_model.py를 실행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 import\n",
    "import os.path as osp\n",
    "import random\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 시드 설정\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 중인 장치: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"사용 중인 장치:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset과 DataLoader를 작성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n",
    "\n",
    "# 파일 경로 리스트를 취득\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath)\n",
    "\n",
    "# Dataset 작성\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "color_mean = (104, 117, 123)  # (BGR) 색의 평균값\n",
    "input_size = 300  # 화상의 input 크기를 300×300으로 설정\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "\n",
    "# DataLoader를 작성\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn)\n",
    "\n",
    "# 사전 오브젝트로 정리\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네트워크 모델을 작성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 중인 장치: cuda:0\n",
      "네트워크 설정 완료: 학습된 가중치를 로드했습니다\n"
     ]
    }
   ],
   "source": [
    "from utils.ssd_model import SSD\n",
    "\n",
    "# SSD300 설정\n",
    "ssd_cfg = {\n",
    "    'num_classes': 21,  # 배경 클래스를 포함한 총 클래스 수\n",
    "    'input_size': 300,  # 화상의 입력 크기\n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 출력할 DBox의 화면비의 종류\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 각 source의 화상 크기\n",
    "    'steps': [8, 16, 32, 64, 100, 300],\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOX의 크기(최소)\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOX의 크기(최대)\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "# SSD 네트워크 모델\n",
    "net = SSD(phase=\"train\", cfg=ssd_cfg)\n",
    "\n",
    "# SSD의 초기 가중치를 설정\n",
    "# ssd의 vgg 부분에 가중치를 로드한다\n",
    "vgg_weights = torch.load('./weights/vgg16_reducedfc.pth')\n",
    "net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "# ssd의 기타 네트워크의 가중치는 He의 초기치로 초기화\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:  # 바이어스 항이 있는 경우\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "# He의 초기치를 적용\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "# GPU를 사용할 수 있는지 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"사용 중인 장치:\", device)\n",
    "\n",
    "print('네트워크 설정 완료: 학습된 가중치를 로드했습니다')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실함수 및 최적화 기법의 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import MultiBoxLoss\n",
    "\n",
    "# 손실함수의 설정\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n",
    "\n",
    "# 최적화 기법의 설정\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 및 검증을 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습시키는 함수 작성\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPU를 사용할 수 있는지 확인\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"사용 중인 장치:\", device)\n",
    "\n",
    "    # 네트워크를 GPU로\n",
    "    net.to(device)\n",
    "\n",
    "    # 네트워크가 어느 정도 고정되면, 고속화시킨다\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 반복자의 카운터 설정\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0  # epoch의 손실합\n",
    "    epoch_val_loss = 0.0  # epoch의 손실합\n",
    "    logs = []\n",
    "\n",
    "    # epoch 루프\n",
    "    for epoch in range(num_epochs+1):\n",
    "\n",
    "        # 시작 시간을 저장\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epoch별 훈련 및 검증을 루프\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # 모델을 훈련모드로\n",
    "                print('(train)')\n",
    "            else:\n",
    "                if((epoch+1) % 10 == 0):\n",
    "                    net.eval()   # 모델을 검증모드로\n",
    "                    print('-------------')\n",
    "                    print('(val)')\n",
    "                else:\n",
    "                    # 검증은 10번에 1번만 실시\n",
    "                    continue\n",
    "\n",
    "            # 데이터 로더에서 minibatch씩 꺼내 루프\n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "\n",
    "                # GPU를 사용할 수 있으면, GPU에 데이터를 보낸다\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device)\n",
    "                           for ann in targets]  # 리스트의 각 요소의 텐서를 GPU로\n",
    "\n",
    "                # optimizer를 초기화\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 순전파(forward) 계산\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 순전파(forward) 계산\n",
    "                    outputs = net(images)\n",
    "\n",
    "                    # 손실 계산\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    # 훈련시에는 역전파(Backpropagation)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()  # 경사 계산\n",
    "\n",
    "                        # 경사가 너무 커지면 계산이 불안정해지므로, clip에서 최대라도 경사 2.0에 고정\n",
    "                        nn.utils.clip_grad_value_(\n",
    "                            net.parameters(), clip_value=2.0)\n",
    "\n",
    "                        optimizer.step()  # 파라미터 갱신\n",
    "\n",
    "                        if (iteration % 10 == 0):  # 10iter에 한 번, loss를 표시\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('반복 {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 검증시\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "\n",
    "        # epoch의 phase 당 loss와 정답률\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        # 로그를 저장\n",
    "        log_epoch = {'epoch': epoch+1,\n",
    "                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output.csv\")\n",
    "\n",
    "        epoch_train_loss = 0.0  # epoch의 손실합\n",
    "        epoch_val_loss = 0.0  # epoch의 손실합\n",
    "\n",
    "        # 네트워크를 저장한다\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), 'weights/ssd300_' +\n",
    "                       str(epoch+1) + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 중인 장치: cuda:0\n",
      "-------------\n",
      "Epoch 1/50\n",
      "-------------\n",
      "(train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/2_objectdetection/utils/data_augumentation.py:246: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 10 || Loss: 15.3722 || 10iter: 53.0672 sec.\n",
      "반복 20 || Loss: 13.9326 || 10iter: 24.9494 sec.\n",
      "반복 30 || Loss: 11.0837 || 10iter: 24.8528 sec.\n",
      "반복 40 || Loss: 10.9187 || 10iter: 24.8813 sec.\n",
      "반복 50 || Loss: 9.5503 || 10iter: 25.2435 sec.\n",
      "반복 60 || Loss: 8.5513 || 10iter: 26.1652 sec.\n",
      "반복 70 || Loss: 8.4516 || 10iter: 24.9801 sec.\n",
      "반복 80 || Loss: 8.1730 || 10iter: 24.7220 sec.\n",
      "반복 90 || Loss: 8.3374 || 10iter: 24.9227 sec.\n",
      "반복 100 || Loss: 7.6921 || 10iter: 25.8274 sec.\n",
      "반복 110 || Loss: 7.8238 || 10iter: 27.1894 sec.\n",
      "반복 120 || Loss: 7.8720 || 10iter: 26.0509 sec.\n",
      "반복 130 || Loss: 8.2793 || 10iter: 26.9762 sec.\n",
      "반복 140 || Loss: 8.2794 || 10iter: 25.5208 sec.\n",
      "반복 150 || Loss: 7.9990 || 10iter: 24.6304 sec.\n",
      "반복 160 || Loss: 8.3543 || 10iter: 24.8144 sec.\n",
      "반복 170 || Loss: 9.0924 || 10iter: 24.6995 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:1731.3374 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  524.0650 sec.\n",
      "-------------\n",
      "Epoch 2/50\n",
      "-------------\n",
      "(train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/2_objectdetection/utils/data_augumentation.py:246: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 180 || Loss: 8.1621 || 10iter: 1.2408 sec.\n",
      "반복 190 || Loss: 8.3499 || 10iter: 25.0080 sec.\n",
      "반복 200 || Loss: 7.9596 || 10iter: 24.8947 sec.\n",
      "반복 210 || Loss: 8.5553 || 10iter: 25.1201 sec.\n",
      "반복 220 || Loss: 8.0360 || 10iter: 25.1553 sec.\n",
      "반복 230 || Loss: 7.3310 || 10iter: 24.7731 sec.\n",
      "반복 240 || Loss: 8.1045 || 10iter: 24.6384 sec.\n",
      "반복 250 || Loss: 7.9535 || 10iter: 25.1596 sec.\n",
      "반복 260 || Loss: 7.9987 || 10iter: 24.9545 sec.\n",
      "반복 270 || Loss: 8.4177 || 10iter: 24.9872 sec.\n",
      "반복 280 || Loss: 7.5128 || 10iter: 25.0828 sec.\n",
      "반복 290 || Loss: 7.6915 || 10iter: 25.2256 sec.\n",
      "반복 300 || Loss: 7.1792 || 10iter: 25.0032 sec.\n",
      "반복 310 || Loss: 7.2222 || 10iter: 25.0377 sec.\n",
      "반복 320 || Loss: 7.1953 || 10iter: 24.8674 sec.\n",
      "반복 330 || Loss: 7.1710 || 10iter: 25.3388 sec.\n",
      "반복 340 || Loss: 7.4834 || 10iter: 25.4341 sec.\n",
      "반복 350 || Loss: 8.0015 || 10iter: 25.4507 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:1371.0475 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  472.5573 sec.\n",
      "-------------\n",
      "Epoch 3/50\n",
      "-------------\n",
      "(train)\n",
      "반복 360 || Loss: 8.0776 || 10iter: 4.0311 sec.\n",
      "반복 370 || Loss: 6.8536 || 10iter: 25.1153 sec.\n",
      "반복 380 || Loss: 7.2581 || 10iter: 25.1138 sec.\n",
      "반복 390 || Loss: 6.9329 || 10iter: 25.3930 sec.\n",
      "반복 400 || Loss: 6.8020 || 10iter: 25.1810 sec.\n",
      "반복 410 || Loss: 7.7421 || 10iter: 24.8843 sec.\n",
      "반복 420 || Loss: 7.0661 || 10iter: 25.0919 sec.\n",
      "반복 430 || Loss: 6.9749 || 10iter: 25.1822 sec.\n",
      "반복 440 || Loss: 6.7702 || 10iter: 24.8900 sec.\n",
      "반복 450 || Loss: 6.6475 || 10iter: 25.0195 sec.\n",
      "반복 460 || Loss: 6.7296 || 10iter: 24.8837 sec.\n",
      "반복 470 || Loss: 7.2144 || 10iter: 24.8865 sec.\n",
      "반복 480 || Loss: 6.9005 || 10iter: 25.2823 sec.\n",
      "반복 490 || Loss: 7.2482 || 10iter: 25.1713 sec.\n",
      "반복 500 || Loss: 6.7246 || 10iter: 24.8878 sec.\n",
      "반복 510 || Loss: 6.9160 || 10iter: 24.9423 sec.\n",
      "반복 520 || Loss: 7.7016 || 10iter: 26.5751 sec.\n",
      "반복 530 || Loss: 6.7432 || 10iter: 27.3684 sec.\n",
      "-------------\n",
      "epoch 3 || Epoch_TRAIN_Loss:1268.7803 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  478.7083 sec.\n",
      "-------------\n",
      "Epoch 4/50\n",
      "-------------\n",
      "(train)\n",
      "반복 540 || Loss: 6.7990 || 10iter: 6.9189 sec.\n",
      "반복 550 || Loss: 6.9787 || 10iter: 26.3520 sec.\n",
      "반복 560 || Loss: 7.4117 || 10iter: 25.0081 sec.\n",
      "반복 570 || Loss: 6.4374 || 10iter: 24.9335 sec.\n",
      "반복 580 || Loss: 6.8863 || 10iter: 24.8952 sec.\n",
      "반복 590 || Loss: 6.2388 || 10iter: 24.7586 sec.\n",
      "반복 600 || Loss: 6.7907 || 10iter: 24.8424 sec.\n",
      "반복 610 || Loss: 6.5735 || 10iter: 24.9517 sec.\n",
      "반복 620 || Loss: 6.7620 || 10iter: 25.1293 sec.\n",
      "반복 630 || Loss: 6.3170 || 10iter: 25.0214 sec.\n",
      "반복 640 || Loss: 6.7940 || 10iter: 25.1300 sec.\n",
      "반복 650 || Loss: 6.1379 || 10iter: 25.1309 sec.\n",
      "반복 660 || Loss: 6.3679 || 10iter: 24.8368 sec.\n",
      "반복 670 || Loss: 6.7392 || 10iter: 24.8899 sec.\n",
      "반복 680 || Loss: 7.1457 || 10iter: 24.9836 sec.\n",
      "반복 690 || Loss: 6.8272 || 10iter: 25.0188 sec.\n",
      "반복 700 || Loss: 6.8246 || 10iter: 26.0060 sec.\n",
      "반복 710 || Loss: 6.6216 || 10iter: 24.9234 sec.\n",
      "-------------\n",
      "epoch 4 || Epoch_TRAIN_Loss:1187.7890 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  473.2636 sec.\n",
      "-------------\n",
      "Epoch 5/50\n",
      "-------------\n",
      "(train)\n",
      "반복 720 || Loss: 6.8240 || 10iter: 9.1024 sec.\n",
      "반복 730 || Loss: 6.7628 || 10iter: 24.9743 sec.\n",
      "반복 740 || Loss: 6.4133 || 10iter: 25.7906 sec.\n",
      "반복 750 || Loss: 7.0212 || 10iter: 25.1199 sec.\n",
      "반복 760 || Loss: 7.0334 || 10iter: 25.0119 sec.\n",
      "반복 770 || Loss: 6.4604 || 10iter: 25.0075 sec.\n",
      "반복 780 || Loss: 6.9315 || 10iter: 24.9926 sec.\n",
      "반복 790 || Loss: 6.3788 || 10iter: 25.2312 sec.\n",
      "반복 800 || Loss: 6.2022 || 10iter: 25.0156 sec.\n",
      "반복 810 || Loss: 6.3553 || 10iter: 25.1204 sec.\n",
      "반복 820 || Loss: 6.1460 || 10iter: 25.1131 sec.\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 검증 실시\n",
    "num_epochs= 50  \n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "끝"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
