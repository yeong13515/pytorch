{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 학습 및 검증 실시\n",
    "\n",
    "- OpenPose 학습과 검증을 실시합니다, AWS의 GPU 머신으로 계산합니다.\n",
    "- p2.xlarge로 45분 정도 걸립니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 목표\n",
    "\n",
    "1.\tOpenPose 학습을 구현할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전 준비\n",
    "\n",
    "- 이전 장에서 구현한 클래스와 함수는 \"utils\" 폴더에 준비되어 있습니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 import\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 설정\n",
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import make_datapath_list, DataTransform, COCOkeypointsDataset\n",
    "\n",
    "# MS COCO 파일 경로 리스트 작성\n",
    "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(\n",
    "    rootpath=\"./data/\")\n",
    "\n",
    "# Dataset 작성\n",
    "# 이 책에서는 데이터 양의 관계로 train을 val_list에서 작성하는 점에 주의\n",
    "train_dataset = COCOkeypointsDataset(\n",
    "    val_img_list, val_mask_list, val_meta_list, phase=\"train\", transform=DataTransform())\n",
    "\n",
    "# 이번에는 간이 학습으로써, 검증 데이터를 작성하지 않음\n",
    "# val_dataset = CocokeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase=\"val\", transform=DataTransform())\n",
    "\n",
    "# DataLoader 작성\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# val_dataloader = data.DataLoader(\n",
    "#    val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 사전형 변수로 정리\n",
    "# dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네트워크 모델 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openpose_net import OpenPoseNet\n",
    "net = OpenPoseNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실함수를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 설정\n",
    "class OpenPoseLoss(nn.Module):\n",
    "    \"\"\"OpenPose의 손실함수 클래스\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OpenPoseLoss, self).__init__()\n",
    "\n",
    "    def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n",
    "        \"\"\"\n",
    "        손실함수 계산.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        saved_for_loss : OpenPoseNet의 출력(리스트)\n",
    "\n",
    "        heatmap_target : [num_batch, 19, 46, 46]\n",
    "            정답 부위의 어노테이션 정보\n",
    "\n",
    "        heatmap_mask : [num_batch, 19, 46, 46]\n",
    "            heatmap 화상의 mask\n",
    "\n",
    "        paf_target : [num_batch, 38, 46, 46]\n",
    "            정답 PAF의 어노테이션 정보\n",
    "\n",
    "        paf_mask : [num_batch, 38, 46, 46]\n",
    "            PAF 화상의 mask\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : 텐서\n",
    "            손실값\n",
    "        \"\"\"\n",
    "\n",
    "        total_loss = 0\n",
    "        # 스테이지마다 계산합니다\n",
    "        for j in range(6):\n",
    "\n",
    "            # PAFs 및 heatmaps에서 마스크된 부분(paf_mask=0 등)은 무시\n",
    "            # PAFs\n",
    "            pred1 = saved_for_loss[2 * j] * paf_mask\n",
    "            gt1 = paf_target.float() * paf_mask\n",
    "\n",
    "            # heatmaps\n",
    "            pred2 = saved_for_loss[2 * j + 1] * heat_mask\n",
    "            gt2 = heatmap_target.float()*heat_mask\n",
    "\n",
    "            total_loss += F.mse_loss(pred1, gt1, reduction='mean') + \\\n",
    "                F.mse_loss(pred2, gt2, reduction='mean')\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "criterion = OpenPoseLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적화 기법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-2,\n",
    "                      momentum=0.9,\n",
    "                      weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습시키는 함수 작성\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPU가 사용 가능한지 확인\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"사용 장치: \", device)\n",
    "\n",
    "    # 네트워크를 GPU로\n",
    "    net.to(device)\n",
    "\n",
    "    # 네트워크가 어느 정도 고정되면, 고속화시킨다\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 화상의 매수\n",
    "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    # 반복 카운터 설정\n",
    "    iteration = 1\n",
    "\n",
    "    # epoch 루프\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 개시 시간을 저장\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        epoch_train_loss = 0.0  # epoch의 손실합\n",
    "        epoch_val_loss = 0.0  # epoch의 손실합\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epoch별 훈련 및 검증 루프\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # 모델을 훈련 모드로\n",
    "                optimizer.zero_grad()\n",
    "                print('(train)')\n",
    "\n",
    "            # 이번에는 검증을 생략\n",
    "            else:\n",
    "                continue\n",
    "                # net.eval()   # 모델을 검증 모드로\n",
    "                # print('-------------')\n",
    "                # print('(val)')\n",
    "\n",
    "            # 데이터 로더에서 minibatch씩 꺼내는 루프\n",
    "            for imges, heatmap_target, heat_mask, paf_target, paf_mask in dataloaders_dict[phase]:\n",
    "                # 미니 배치 크기가 1이면, 배치 노멀라이제이션에서 에러가 발생하므로 피한다\n",
    "                if imges.size()[0] == 1:\n",
    "                    continue\n",
    "\n",
    "                # GPU가 사용 가능하면 GPU로 데이터를 보낸다\n",
    "                imges = imges.to(device)\n",
    "                heatmap_target = heatmap_target.to(device)\n",
    "                heat_mask = heat_mask.to(device)\n",
    "                paf_target = paf_target.to(device)\n",
    "                paf_mask = paf_mask.to(device)\n",
    "\n",
    "                # optimizer 초기화\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 순전파(forward) 계산\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # (out6_1, out6_2)는 사용하지 않으므로 _ 로 대체\n",
    "                    _, saved_for_loss = net(imges)\n",
    "\n",
    "                    loss = criterion(saved_for_loss, heatmap_target,\n",
    "                                     heat_mask, paf_target, paf_mask)\n",
    "                    del saved_for_loss\n",
    "                    # 훈련시에는 역전파\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if (iteration % 10 == 0):  # 10iter에 1번, loss를 표시\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('반복 {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item()/batch_size, duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 검증시\n",
    "                    # else:\n",
    "                        #epoch_val_loss += loss.item()\n",
    "\n",
    "        # epoch의 phase별 loss와 정답률\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss/num_train_imgs, 0))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "    # 마지막 네트워크를 저장한다\n",
    "    torch.save(net.state_dict(), 'weights/openpose_net_' +\n",
    "               str(epoch+1) + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 장치:  cuda:0\n",
      "-------------\n",
      "Epoch 1/2\n",
      "-------------\n",
      "(train)\n",
      "반복 10 || Loss: 0.0094 || 10iter: 113.7127 sec.\n",
      "반복 20 || Loss: 0.0082 || 10iter: 90.4145 sec.\n",
      "반복 30 || Loss: 0.0069 || 10iter: 88.4890 sec.\n",
      "반복 40 || Loss: 0.0058 || 10iter: 90.9961 sec.\n",
      "반복 50 || Loss: 0.0050 || 10iter: 90.8274 sec.\n",
      "반복 60 || Loss: 0.0042 || 10iter: 89.7553 sec.\n",
      "반복 70 || Loss: 0.0038 || 10iter: 91.1155 sec.\n",
      "반복 80 || Loss: 0.0031 || 10iter: 91.3307 sec.\n",
      "반복 90 || Loss: 0.0027 || 10iter: 91.7214 sec.\n",
      "반복 100 || Loss: 0.0026 || 10iter: 92.2645 sec.\n",
      "반복 110 || Loss: 0.0023 || 10iter: 91.7421 sec.\n",
      "반복 120 || Loss: 0.0020 || 10iter: 90.7930 sec.\n",
      "반복 130 || Loss: 0.0020 || 10iter: 91.3045 sec.\n",
      "반복 140 || Loss: 0.0019 || 10iter: 91.6105 sec.\n",
      "반복 150 || Loss: 0.0016 || 10iter: 90.2619 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:0.0043 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  1462.0789 sec.\n",
      "-------------\n",
      "Epoch 2/2\n",
      "-------------\n",
      "(train)\n",
      "반복 160 || Loss: 0.0017 || 10iter: 64.3399 sec.\n",
      "반복 170 || Loss: 0.0017 || 10iter: 91.2324 sec.\n",
      "반복 180 || Loss: 0.0015 || 10iter: 92.3138 sec.\n",
      "반복 190 || Loss: 0.0015 || 10iter: 90.3904 sec.\n",
      "반복 200 || Loss: 0.0015 || 10iter: 90.9617 sec.\n",
      "반복 210 || Loss: 0.0016 || 10iter: 91.2119 sec.\n",
      "반복 220 || Loss: 0.0014 || 10iter: 90.6868 sec.\n",
      "반복 230 || Loss: 0.0016 || 10iter: 90.8710 sec.\n",
      "반복 240 || Loss: 0.0017 || 10iter: 90.3973 sec.\n",
      "반복 250 || Loss: 0.0014 || 10iter: 90.8158 sec.\n",
      "반복 260 || Loss: 0.0012 || 10iter: 92.8508 sec.\n",
      "반복 270 || Loss: 0.0012 || 10iter: 91.9698 sec.\n",
      "반복 280 || Loss: 0.0015 || 10iter: 90.8905 sec.\n",
      "반복 290 || Loss: 0.0011 || 10iter: 91.2742 sec.\n",
      "반복 300 || Loss: 0.0012 || 10iter: 91.0789 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:0.0015 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  1437.0403 sec.\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 검증을 실행한다\n",
    "num_epochs = 2\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "끝"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}