{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECO 모델의 추론\n",
    "\n",
    "ECO 모델을 구현하고, 동영상 데이터의 클래스 분류를 수행합니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.5 학습 목표\n",
    "\n",
    "1.\tECO 모델을 구현할 수 있다\n",
    "2.\t학습된 ECO 모델을 자신의 모델에 로드할 수 있다\n",
    "3.\tECO 모델을 사용하여, 테스트 데이터를 추론할 수 있다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전 준비\n",
    "\n",
    "- \"weights\" 폴더에 다운로드한 \"ECO_Lite_rgb_model_Kinetics.pth.tar\"를 배치하세요.\n",
    "\n",
    "https://github.com/mzolfaghari/ECO-pytorch 의\n",
    "\n",
    "https://drive.google.com/open?id=1XNIq7byciKgrn011jLBggd2g79jKX4uD\n",
    "\n",
    "\n",
    "- 9.2부터 9.4절까지 구현한 내용을 \"utils\"에 준비해놓고 있습니다.\n",
    "\n",
    "이를 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights 폴더가 없으면 작성한다\n",
    "weights_dir = \"./weights/\"\n",
    "if not os.path.exists(weights_dir):\n",
    "    os.mkdir(weights_dir)\n",
    "\n",
    "# \"weights\" 폴더에 학습된 모델 \"ECO_Lite_rgb_model_Kinetics.pth.tar\"를 다운로드하여 배치하세요.\n",
    "# https://github.com/mzolfaghari/ECO-pytorch 의\n",
    "# https://drive.google.com/open?id=1XNIq7byciKgrn011jLBggd2g79jKX4uD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kinematics 동영상 데이터 세트의 DataLoader를 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from utils.kinetics400_eco_dataloader import make_datapath_list, VideoTransform, get_label_id_dictionary, VideoDataset\n",
    "\n",
    "# vieo_list 작성\n",
    "root_path = './data/kinetics_videos/'\n",
    "video_list = make_datapath_list(root_path)\n",
    "\n",
    "# 전처리 설정\n",
    "resize, crop_size = 224, 224\n",
    "mean, std = [104, 117, 123], [1, 1, 1]\n",
    "video_transform = VideoTransform(resize, crop_size, mean, std)\n",
    "\n",
    "# 라벨 사전 작성\n",
    "label_dicitionary_path = './video_download/kinetics_400_label_dicitionary.csv'\n",
    "label_id_dict, id_label_dict = get_label_id_dictionary(label_dicitionary_path)\n",
    "\n",
    "# Dataset 작성\n",
    "# num_segments 는 동영상을 어떻게 분할해 사용할지를 결정\n",
    "val_dataset = VideoDataset(video_list, label_id_dict, num_segments=16,\n",
    "                           phase=\"val\", transform=video_transform, img_tmpl='image_{:05d}.jpg')\n",
    "\n",
    "# DataLoader로 합니다\n",
    "batch_size = 8\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 동작 확인\n",
    "batch_iterator = iter(val_dataloader)  # 반복자로 변환\n",
    "imgs_transformeds, labels, label_ids, dir_path = next(\n",
    "    batch_iterator)  # 1번째 요소를 꺼낸다\n",
    "print(imgs_transformeds.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECO 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eco import ECO_2D, ECO_3D\n",
    "\n",
    "class ECO_Lite(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECO_Lite, self).__init__()\n",
    "\n",
    "        # 2D Net 모듈\n",
    "        self.eco_2d = ECO_2D()\n",
    "\n",
    "        # 3D Net 모듈\n",
    "        self.eco_3d = ECO_3D()\n",
    "\n",
    "        # 클래스 분류의 전결합층\n",
    "        self.fc_final = nn.Linear(in_features=512, out_features=400, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        입력 x는 torch.Size([batch_num, num_segments=16, 3, 224, 224]))\n",
    "        '''\n",
    "\n",
    "        # 입력 x의 각 차원의 크기를 취득\n",
    "        bs, ns, c, h, w = x.shape\n",
    "\n",
    "        # x를 (bs*ns, c, h, w)로 크기를 변환한다\n",
    "        out = x.view(-1, c, h, w)\n",
    "        # (주석)\n",
    "        # PyTorch의 Conv2D는 입력 크기가 (batch_num, c, h, w)만 허용되므로\n",
    "        # (batch_num, num_segments, c, h, w)는 처리할 수 없다\n",
    "        # 지금은 2차원 화상을 따로 처리하므로, num_segments는 batch_num의 차원에 넣어도 좋으므로\n",
    "        # (batch_num×num_segments, c, h, w)로 크기를 변환한다\n",
    "\n",
    "        # 2D Net 모듈 출력 torch.Size([batch_num×16, 96, 28, 28])\n",
    "        out = self.eco_2d(out)\n",
    "\n",
    "        # 2차원 화상을 텐서로 3차원용으로 변환\n",
    "        # num_segments를 batch_num의 차원으로 넣은 것을 원래대로 되돌림\n",
    "        out = out.view(-1, ns, 96, 28, 28)\n",
    "\n",
    "        # 3D Net 모듈 출력 torch.Size([batch_num, 512])\n",
    "        out = self.eco_3d(out)\n",
    "\n",
    "        # 클래스 분류의 전결합층 출력 torch.Size([batch_num, class_num=400])\n",
    "        out = self.fc_final(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECO_Lite(\n",
       "  (eco_2d): ECO_2D(\n",
       "    (basic_conv): BasicConv(\n",
       "      (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1_relu_7x7): ReLU(inplace)\n",
       "      (pool1_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_relu_3x3_reduce): ReLU(inplace)\n",
       "      (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_relu_3x3): ReLU(inplace)\n",
       "      (pool2_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    )\n",
       "    (inception_a): InceptionA(\n",
       "      (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_1x1): ReLU(inplace)\n",
       "      (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_3x3): ReLU(inplace)\n",
       "      (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_double_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_double_3x3_1): ReLU(inplace)\n",
       "      (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_double_3x3_2): ReLU(inplace)\n",
       "      (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_pool_proj): ReLU(inplace)\n",
       "    )\n",
       "    (inception_b): InceptionB(\n",
       "      (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_1x1): ReLU(inplace)\n",
       "      (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_3x3): ReLU(inplace)\n",
       "      (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_double_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_double_3x3_1): ReLU(inplace)\n",
       "      (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_double_3x3_2): ReLU(inplace)\n",
       "      (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_pool_proj): ReLU(inplace)\n",
       "    )\n",
       "    (inception_c): InceptionC(\n",
       "      (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3c_relu_double_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3c_relu_double_3x3_1): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (eco_3d): ECO_3D(\n",
       "    (res_3d_3): Resnet_3D_3(\n",
       "      (res3a_2): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res3a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res3a_relu): ReLU(inplace)\n",
       "      (res3b_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res3b_1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res3b_1_relu): ReLU(inplace)\n",
       "      (res3b_2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res3b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res3b_relu): ReLU(inplace)\n",
       "    )\n",
       "    (res_3d_4): Resnet_3D_4(\n",
       "      (res4a_1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res4a_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4a_1_relu): ReLU(inplace)\n",
       "      (res4a_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res4a_down): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res4a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4a_relu): ReLU(inplace)\n",
       "      (res4b_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res4b_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4b_1_relu): ReLU(inplace)\n",
       "      (res4b_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res4b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4b_relu): ReLU(inplace)\n",
       "    )\n",
       "    (res_3d_5): Resnet_3D_5(\n",
       "      (res5a_1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res5a_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5a_1_relu): ReLU(inplace)\n",
       "      (res5a_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res5a_down): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res5a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5a_relu): ReLU(inplace)\n",
       "      (res5b_1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res5b_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5b_1_relu): ReLU(inplace)\n",
       "      (res5b_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res5b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5b_relu): ReLU(inplace)\n",
       "    )\n",
       "    (global_pool): AvgPool3d(kernel_size=(4, 7, 7), stride=1, padding=0)\n",
       "  )\n",
       "  (fc_final): Linear(in_features=512, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ECO_Lite()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 확습된 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 파라미터를 로드합니다\n",
      "module.base_model.conv1_7x7_s2.weight→eco_2d.basic_conv.conv1_7x7_s2.weight\n",
      "module.base_model.conv1_7x7_s2.bias→eco_2d.basic_conv.conv1_7x7_s2.bias\n",
      "module.base_model.conv1_7x7_s2_bn.weight→eco_2d.basic_conv.conv1_7x7_s2_bn.weight\n",
      "module.base_model.conv1_7x7_s2_bn.bias→eco_2d.basic_conv.conv1_7x7_s2_bn.bias\n",
      "module.base_model.conv1_7x7_s2_bn.running_mean→eco_2d.basic_conv.conv1_7x7_s2_bn.running_mean\n",
      "module.base_model.conv1_7x7_s2_bn.running_var→eco_2d.basic_conv.conv1_7x7_s2_bn.running_var\n",
      "module.base_model.conv1_7x7_s2_bn.num_batches_tracked→eco_2d.basic_conv.conv1_7x7_s2_bn.num_batches_tracked\n",
      "module.base_model.conv2_3x3_reduce.weight→eco_2d.basic_conv.conv2_3x3_reduce.weight\n",
      "module.base_model.conv2_3x3_reduce.bias→eco_2d.basic_conv.conv2_3x3_reduce.bias\n",
      "module.base_model.conv2_3x3_reduce_bn.weight→eco_2d.basic_conv.conv2_3x3_reduce_bn.weight\n",
      "module.base_model.conv2_3x3_reduce_bn.bias→eco_2d.basic_conv.conv2_3x3_reduce_bn.bias\n",
      "module.base_model.conv2_3x3_reduce_bn.running_mean→eco_2d.basic_conv.conv2_3x3_reduce_bn.running_mean\n",
      "module.base_model.conv2_3x3_reduce_bn.running_var→eco_2d.basic_conv.conv2_3x3_reduce_bn.running_var\n",
      "module.base_model.conv2_3x3_reduce_bn.num_batches_tracked→eco_2d.basic_conv.conv2_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.conv2_3x3.weight→eco_2d.basic_conv.conv2_3x3.weight\n",
      "module.base_model.conv2_3x3.bias→eco_2d.basic_conv.conv2_3x3.bias\n",
      "module.base_model.conv2_3x3_bn.weight→eco_2d.basic_conv.conv2_3x3_bn.weight\n",
      "module.base_model.conv2_3x3_bn.bias→eco_2d.basic_conv.conv2_3x3_bn.bias\n",
      "module.base_model.conv2_3x3_bn.running_mean→eco_2d.basic_conv.conv2_3x3_bn.running_mean\n",
      "module.base_model.conv2_3x3_bn.running_var→eco_2d.basic_conv.conv2_3x3_bn.running_var\n",
      "module.base_model.conv2_3x3_bn.num_batches_tracked→eco_2d.basic_conv.conv2_3x3_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_1x1.weight→eco_2d.inception_a.inception_3a_1x1.weight\n",
      "module.base_model.inception_3a_1x1.bias→eco_2d.inception_a.inception_3a_1x1.bias\n",
      "module.base_model.inception_3a_1x1_bn.weight→eco_2d.inception_a.inception_3a_1x1_bn.weight\n",
      "module.base_model.inception_3a_1x1_bn.bias→eco_2d.inception_a.inception_3a_1x1_bn.bias\n",
      "module.base_model.inception_3a_1x1_bn.running_mean→eco_2d.inception_a.inception_3a_1x1_bn.running_mean\n",
      "module.base_model.inception_3a_1x1_bn.running_var→eco_2d.inception_a.inception_3a_1x1_bn.running_var\n",
      "module.base_model.inception_3a_1x1_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_1x1_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_3x3_reduce.weight→eco_2d.inception_a.inception_3a_3x3_reduce.weight\n",
      "module.base_model.inception_3a_3x3_reduce.bias→eco_2d.inception_a.inception_3a_3x3_reduce.bias\n",
      "module.base_model.inception_3a_3x3_reduce_bn.weight→eco_2d.inception_a.inception_3a_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3a_3x3_reduce_bn.bias→eco_2d.inception_a.inception_3a_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3a_3x3_reduce_bn.running_mean→eco_2d.inception_a.inception_3a_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3a_3x3_reduce_bn.running_var→eco_2d.inception_a.inception_3a_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3a_3x3_reduce_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_3x3.weight→eco_2d.inception_a.inception_3a_3x3.weight\n",
      "module.base_model.inception_3a_3x3.bias→eco_2d.inception_a.inception_3a_3x3.bias\n",
      "module.base_model.inception_3a_3x3_bn.weight→eco_2d.inception_a.inception_3a_3x3_bn.weight\n",
      "module.base_model.inception_3a_3x3_bn.bias→eco_2d.inception_a.inception_3a_3x3_bn.bias\n",
      "module.base_model.inception_3a_3x3_bn.running_mean→eco_2d.inception_a.inception_3a_3x3_bn.running_mean\n",
      "module.base_model.inception_3a_3x3_bn.running_var→eco_2d.inception_a.inception_3a_3x3_bn.running_var\n",
      "module.base_model.inception_3a_3x3_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_3x3_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_double_3x3_reduce.weight→eco_2d.inception_a.inception_3a_double_3x3_reduce.weight\n",
      "module.base_model.inception_3a_double_3x3_reduce.bias→eco_2d.inception_a.inception_3a_double_3x3_reduce.bias\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.weight→eco_2d.inception_a.inception_3a_double_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.bias→eco_2d.inception_a.inception_3a_double_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.running_mean→eco_2d.inception_a.inception_3a_double_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.running_var→eco_2d.inception_a.inception_3a_double_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_double_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_double_3x3_1.weight→eco_2d.inception_a.inception_3a_double_3x3_1.weight\n",
      "module.base_model.inception_3a_double_3x3_1.bias→eco_2d.inception_a.inception_3a_double_3x3_1.bias\n",
      "module.base_model.inception_3a_double_3x3_1_bn.weight→eco_2d.inception_a.inception_3a_double_3x3_1_bn.weight\n",
      "module.base_model.inception_3a_double_3x3_1_bn.bias→eco_2d.inception_a.inception_3a_double_3x3_1_bn.bias\n",
      "module.base_model.inception_3a_double_3x3_1_bn.running_mean→eco_2d.inception_a.inception_3a_double_3x3_1_bn.running_mean\n",
      "module.base_model.inception_3a_double_3x3_1_bn.running_var→eco_2d.inception_a.inception_3a_double_3x3_1_bn.running_var\n",
      "module.base_model.inception_3a_double_3x3_1_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_double_3x3_1_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_double_3x3_2.weight→eco_2d.inception_a.inception_3a_double_3x3_2.weight\n",
      "module.base_model.inception_3a_double_3x3_2.bias→eco_2d.inception_a.inception_3a_double_3x3_2.bias\n",
      "module.base_model.inception_3a_double_3x3_2_bn.weight→eco_2d.inception_a.inception_3a_double_3x3_2_bn.weight\n",
      "module.base_model.inception_3a_double_3x3_2_bn.bias→eco_2d.inception_a.inception_3a_double_3x3_2_bn.bias\n",
      "module.base_model.inception_3a_double_3x3_2_bn.running_mean→eco_2d.inception_a.inception_3a_double_3x3_2_bn.running_mean\n",
      "module.base_model.inception_3a_double_3x3_2_bn.running_var→eco_2d.inception_a.inception_3a_double_3x3_2_bn.running_var\n",
      "module.base_model.inception_3a_double_3x3_2_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_double_3x3_2_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_pool_proj.weight→eco_2d.inception_a.inception_3a_pool_proj.weight\n",
      "module.base_model.inception_3a_pool_proj.bias→eco_2d.inception_a.inception_3a_pool_proj.bias\n",
      "module.base_model.inception_3a_pool_proj_bn.weight→eco_2d.inception_a.inception_3a_pool_proj_bn.weight\n",
      "module.base_model.inception_3a_pool_proj_bn.bias→eco_2d.inception_a.inception_3a_pool_proj_bn.bias\n",
      "module.base_model.inception_3a_pool_proj_bn.running_mean→eco_2d.inception_a.inception_3a_pool_proj_bn.running_mean\n",
      "module.base_model.inception_3a_pool_proj_bn.running_var→eco_2d.inception_a.inception_3a_pool_proj_bn.running_var\n",
      "module.base_model.inception_3a_pool_proj_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_pool_proj_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_1x1.weight→eco_2d.inception_b.inception_3b_1x1.weight\n",
      "module.base_model.inception_3b_1x1.bias→eco_2d.inception_b.inception_3b_1x1.bias\n",
      "module.base_model.inception_3b_1x1_bn.weight→eco_2d.inception_b.inception_3b_1x1_bn.weight\n",
      "module.base_model.inception_3b_1x1_bn.bias→eco_2d.inception_b.inception_3b_1x1_bn.bias\n",
      "module.base_model.inception_3b_1x1_bn.running_mean→eco_2d.inception_b.inception_3b_1x1_bn.running_mean\n",
      "module.base_model.inception_3b_1x1_bn.running_var→eco_2d.inception_b.inception_3b_1x1_bn.running_var\n",
      "module.base_model.inception_3b_1x1_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_1x1_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_3x3_reduce.weight→eco_2d.inception_b.inception_3b_3x3_reduce.weight\n",
      "module.base_model.inception_3b_3x3_reduce.bias→eco_2d.inception_b.inception_3b_3x3_reduce.bias\n",
      "module.base_model.inception_3b_3x3_reduce_bn.weight→eco_2d.inception_b.inception_3b_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3b_3x3_reduce_bn.bias→eco_2d.inception_b.inception_3b_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3b_3x3_reduce_bn.running_mean→eco_2d.inception_b.inception_3b_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3b_3x3_reduce_bn.running_var→eco_2d.inception_b.inception_3b_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3b_3x3_reduce_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_3x3.weight→eco_2d.inception_b.inception_3b_3x3.weight\n",
      "module.base_model.inception_3b_3x3.bias→eco_2d.inception_b.inception_3b_3x3.bias\n",
      "module.base_model.inception_3b_3x3_bn.weight→eco_2d.inception_b.inception_3b_3x3_bn.weight\n",
      "module.base_model.inception_3b_3x3_bn.bias→eco_2d.inception_b.inception_3b_3x3_bn.bias\n",
      "module.base_model.inception_3b_3x3_bn.running_mean→eco_2d.inception_b.inception_3b_3x3_bn.running_mean\n",
      "module.base_model.inception_3b_3x3_bn.running_var→eco_2d.inception_b.inception_3b_3x3_bn.running_var\n",
      "module.base_model.inception_3b_3x3_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_3x3_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_double_3x3_reduce.weight→eco_2d.inception_b.inception_3b_double_3x3_reduce.weight\n",
      "module.base_model.inception_3b_double_3x3_reduce.bias→eco_2d.inception_b.inception_3b_double_3x3_reduce.bias\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.weight→eco_2d.inception_b.inception_3b_double_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.bias→eco_2d.inception_b.inception_3b_double_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.running_mean→eco_2d.inception_b.inception_3b_double_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.running_var→eco_2d.inception_b.inception_3b_double_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_double_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_double_3x3_1.weight→eco_2d.inception_b.inception_3b_double_3x3_1.weight\n",
      "module.base_model.inception_3b_double_3x3_1.bias→eco_2d.inception_b.inception_3b_double_3x3_1.bias\n",
      "module.base_model.inception_3b_double_3x3_1_bn.weight→eco_2d.inception_b.inception_3b_double_3x3_1_bn.weight\n",
      "module.base_model.inception_3b_double_3x3_1_bn.bias→eco_2d.inception_b.inception_3b_double_3x3_1_bn.bias\n",
      "module.base_model.inception_3b_double_3x3_1_bn.running_mean→eco_2d.inception_b.inception_3b_double_3x3_1_bn.running_mean\n",
      "module.base_model.inception_3b_double_3x3_1_bn.running_var→eco_2d.inception_b.inception_3b_double_3x3_1_bn.running_var\n",
      "module.base_model.inception_3b_double_3x3_1_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_double_3x3_1_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_double_3x3_2.weight→eco_2d.inception_b.inception_3b_double_3x3_2.weight\n",
      "module.base_model.inception_3b_double_3x3_2.bias→eco_2d.inception_b.inception_3b_double_3x3_2.bias\n",
      "module.base_model.inception_3b_double_3x3_2_bn.weight→eco_2d.inception_b.inception_3b_double_3x3_2_bn.weight\n",
      "module.base_model.inception_3b_double_3x3_2_bn.bias→eco_2d.inception_b.inception_3b_double_3x3_2_bn.bias\n",
      "module.base_model.inception_3b_double_3x3_2_bn.running_mean→eco_2d.inception_b.inception_3b_double_3x3_2_bn.running_mean\n",
      "module.base_model.inception_3b_double_3x3_2_bn.running_var→eco_2d.inception_b.inception_3b_double_3x3_2_bn.running_var\n",
      "module.base_model.inception_3b_double_3x3_2_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_double_3x3_2_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_pool_proj.weight→eco_2d.inception_b.inception_3b_pool_proj.weight\n",
      "module.base_model.inception_3b_pool_proj.bias→eco_2d.inception_b.inception_3b_pool_proj.bias\n",
      "module.base_model.inception_3b_pool_proj_bn.weight→eco_2d.inception_b.inception_3b_pool_proj_bn.weight\n",
      "module.base_model.inception_3b_pool_proj_bn.bias→eco_2d.inception_b.inception_3b_pool_proj_bn.bias\n",
      "module.base_model.inception_3b_pool_proj_bn.running_mean→eco_2d.inception_b.inception_3b_pool_proj_bn.running_mean\n",
      "module.base_model.inception_3b_pool_proj_bn.running_var→eco_2d.inception_b.inception_3b_pool_proj_bn.running_var\n",
      "module.base_model.inception_3b_pool_proj_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_pool_proj_bn.num_batches_tracked\n",
      "module.base_model.inception_3c_double_3x3_reduce.weight→eco_2d.inception_c.inception_3c_double_3x3_reduce.weight\n",
      "module.base_model.inception_3c_double_3x3_reduce.bias→eco_2d.inception_c.inception_3c_double_3x3_reduce.bias\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.weight→eco_2d.inception_c.inception_3c_double_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.bias→eco_2d.inception_c.inception_3c_double_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.running_mean→eco_2d.inception_c.inception_3c_double_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.running_var→eco_2d.inception_c.inception_3c_double_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.num_batches_tracked→eco_2d.inception_c.inception_3c_double_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3c_double_3x3_1.weight→eco_2d.inception_c.inception_3c_double_3x3_1.weight\n",
      "module.base_model.inception_3c_double_3x3_1.bias→eco_2d.inception_c.inception_3c_double_3x3_1.bias\n",
      "module.base_model.inception_3c_double_3x3_1_bn.weight→eco_2d.inception_c.inception_3c_double_3x3_1_bn.weight\n",
      "module.base_model.inception_3c_double_3x3_1_bn.bias→eco_2d.inception_c.inception_3c_double_3x3_1_bn.bias\n",
      "module.base_model.inception_3c_double_3x3_1_bn.running_mean→eco_2d.inception_c.inception_3c_double_3x3_1_bn.running_mean\n",
      "module.base_model.inception_3c_double_3x3_1_bn.running_var→eco_2d.inception_c.inception_3c_double_3x3_1_bn.running_var\n",
      "module.base_model.inception_3c_double_3x3_1_bn.num_batches_tracked→eco_2d.inception_c.inception_3c_double_3x3_1_bn.num_batches_tracked\n",
      "module.base_model.res3a_2.weight→eco_3d.res_3d_3.res3a_2.weight\n",
      "module.base_model.res3a_2.bias→eco_3d.res_3d_3.res3a_2.bias\n",
      "module.base_model.res3a_bn.weight→eco_3d.res_3d_3.res3a_bn.weight\n",
      "module.base_model.res3a_bn.bias→eco_3d.res_3d_3.res3a_bn.bias\n",
      "module.base_model.res3a_bn.running_mean→eco_3d.res_3d_3.res3a_bn.running_mean\n",
      "module.base_model.res3a_bn.running_var→eco_3d.res_3d_3.res3a_bn.running_var\n",
      "module.base_model.res3a_bn.num_batches_tracked→eco_3d.res_3d_3.res3a_bn.num_batches_tracked\n",
      "module.base_model.res3b_1.weight→eco_3d.res_3d_3.res3b_1.weight\n",
      "module.base_model.res3b_1.bias→eco_3d.res_3d_3.res3b_1.bias\n",
      "module.base_model.res3b_1_bn.weight→eco_3d.res_3d_3.res3b_1_bn.weight\n",
      "module.base_model.res3b_1_bn.bias→eco_3d.res_3d_3.res3b_1_bn.bias\n",
      "module.base_model.res3b_1_bn.running_mean→eco_3d.res_3d_3.res3b_1_bn.running_mean\n",
      "module.base_model.res3b_1_bn.running_var→eco_3d.res_3d_3.res3b_1_bn.running_var\n",
      "module.base_model.res3b_1_bn.num_batches_tracked→eco_3d.res_3d_3.res3b_1_bn.num_batches_tracked\n",
      "module.base_model.res3b_2.weight→eco_3d.res_3d_3.res3b_2.weight\n",
      "module.base_model.res3b_2.bias→eco_3d.res_3d_3.res3b_2.bias\n",
      "module.base_model.res3b_bn.weight→eco_3d.res_3d_3.res3b_bn.weight\n",
      "module.base_model.res3b_bn.bias→eco_3d.res_3d_3.res3b_bn.bias\n",
      "module.base_model.res3b_bn.running_mean→eco_3d.res_3d_3.res3b_bn.running_mean\n",
      "module.base_model.res3b_bn.running_var→eco_3d.res_3d_3.res3b_bn.running_var\n",
      "module.base_model.res3b_bn.num_batches_tracked→eco_3d.res_3d_3.res3b_bn.num_batches_tracked\n",
      "module.base_model.res4a_1.weight→eco_3d.res_3d_4.res4a_1.weight\n",
      "module.base_model.res4a_1.bias→eco_3d.res_3d_4.res4a_1.bias\n",
      "module.base_model.res4a_1_bn.weight→eco_3d.res_3d_4.res4a_1_bn.weight\n",
      "module.base_model.res4a_1_bn.bias→eco_3d.res_3d_4.res4a_1_bn.bias\n",
      "module.base_model.res4a_1_bn.running_mean→eco_3d.res_3d_4.res4a_1_bn.running_mean\n",
      "module.base_model.res4a_1_bn.running_var→eco_3d.res_3d_4.res4a_1_bn.running_var\n",
      "module.base_model.res4a_1_bn.num_batches_tracked→eco_3d.res_3d_4.res4a_1_bn.num_batches_tracked\n",
      "module.base_model.res4a_2.weight→eco_3d.res_3d_4.res4a_2.weight\n",
      "module.base_model.res4a_2.bias→eco_3d.res_3d_4.res4a_2.bias\n",
      "module.base_model.res4a_down.weight→eco_3d.res_3d_4.res4a_down.weight\n",
      "module.base_model.res4a_down.bias→eco_3d.res_3d_4.res4a_down.bias\n",
      "module.base_model.res4a_bn.weight→eco_3d.res_3d_4.res4a_bn.weight\n",
      "module.base_model.res4a_bn.bias→eco_3d.res_3d_4.res4a_bn.bias\n",
      "module.base_model.res4a_bn.running_mean→eco_3d.res_3d_4.res4a_bn.running_mean\n",
      "module.base_model.res4a_bn.running_var→eco_3d.res_3d_4.res4a_bn.running_var\n",
      "module.base_model.res4a_bn.num_batches_tracked→eco_3d.res_3d_4.res4a_bn.num_batches_tracked\n",
      "module.base_model.res4b_1.weight→eco_3d.res_3d_4.res4b_1.weight\n",
      "module.base_model.res4b_1.bias→eco_3d.res_3d_4.res4b_1.bias\n",
      "module.base_model.res4b_1_bn.weight→eco_3d.res_3d_4.res4b_1_bn.weight\n",
      "module.base_model.res4b_1_bn.bias→eco_3d.res_3d_4.res4b_1_bn.bias\n",
      "module.base_model.res4b_1_bn.running_mean→eco_3d.res_3d_4.res4b_1_bn.running_mean\n",
      "module.base_model.res4b_1_bn.running_var→eco_3d.res_3d_4.res4b_1_bn.running_var\n",
      "module.base_model.res4b_1_bn.num_batches_tracked→eco_3d.res_3d_4.res4b_1_bn.num_batches_tracked\n",
      "module.base_model.res4b_2.weight→eco_3d.res_3d_4.res4b_2.weight\n",
      "module.base_model.res4b_2.bias→eco_3d.res_3d_4.res4b_2.bias\n",
      "module.base_model.res4b_bn.weight→eco_3d.res_3d_4.res4b_bn.weight\n",
      "module.base_model.res4b_bn.bias→eco_3d.res_3d_4.res4b_bn.bias\n",
      "module.base_model.res4b_bn.running_mean→eco_3d.res_3d_4.res4b_bn.running_mean\n",
      "module.base_model.res4b_bn.running_var→eco_3d.res_3d_4.res4b_bn.running_var\n",
      "module.base_model.res4b_bn.num_batches_tracked→eco_3d.res_3d_4.res4b_bn.num_batches_tracked\n",
      "module.base_model.res5a_1.weight→eco_3d.res_3d_5.res5a_1.weight\n",
      "module.base_model.res5a_1.bias→eco_3d.res_3d_5.res5a_1.bias\n",
      "module.base_model.res5a_1_bn.weight→eco_3d.res_3d_5.res5a_1_bn.weight\n",
      "module.base_model.res5a_1_bn.bias→eco_3d.res_3d_5.res5a_1_bn.bias\n",
      "module.base_model.res5a_1_bn.running_mean→eco_3d.res_3d_5.res5a_1_bn.running_mean\n",
      "module.base_model.res5a_1_bn.running_var→eco_3d.res_3d_5.res5a_1_bn.running_var\n",
      "module.base_model.res5a_1_bn.num_batches_tracked→eco_3d.res_3d_5.res5a_1_bn.num_batches_tracked\n",
      "module.base_model.res5a_2.weight→eco_3d.res_3d_5.res5a_2.weight\n",
      "module.base_model.res5a_2.bias→eco_3d.res_3d_5.res5a_2.bias\n",
      "module.base_model.res5a_down.weight→eco_3d.res_3d_5.res5a_down.weight\n",
      "module.base_model.res5a_down.bias→eco_3d.res_3d_5.res5a_down.bias\n",
      "module.base_model.res5a_bn.weight→eco_3d.res_3d_5.res5a_bn.weight\n",
      "module.base_model.res5a_bn.bias→eco_3d.res_3d_5.res5a_bn.bias\n",
      "module.base_model.res5a_bn.running_mean→eco_3d.res_3d_5.res5a_bn.running_mean\n",
      "module.base_model.res5a_bn.running_var→eco_3d.res_3d_5.res5a_bn.running_var\n",
      "module.base_model.res5a_bn.num_batches_tracked→eco_3d.res_3d_5.res5a_bn.num_batches_tracked\n",
      "module.base_model.res5b_1.weight→eco_3d.res_3d_5.res5b_1.weight\n",
      "module.base_model.res5b_1.bias→eco_3d.res_3d_5.res5b_1.bias\n",
      "module.base_model.res5b_1_bn.weight→eco_3d.res_3d_5.res5b_1_bn.weight\n",
      "module.base_model.res5b_1_bn.bias→eco_3d.res_3d_5.res5b_1_bn.bias\n",
      "module.base_model.res5b_1_bn.running_mean→eco_3d.res_3d_5.res5b_1_bn.running_mean\n",
      "module.base_model.res5b_1_bn.running_var→eco_3d.res_3d_5.res5b_1_bn.running_var\n",
      "module.base_model.res5b_1_bn.num_batches_tracked→eco_3d.res_3d_5.res5b_1_bn.num_batches_tracked\n",
      "module.base_model.res5b_2.weight→eco_3d.res_3d_5.res5b_2.weight\n",
      "module.base_model.res5b_2.bias→eco_3d.res_3d_5.res5b_2.bias\n",
      "module.base_model.res5b_bn.weight→eco_3d.res_3d_5.res5b_bn.weight\n",
      "module.base_model.res5b_bn.bias→eco_3d.res_3d_5.res5b_bn.bias\n",
      "module.base_model.res5b_bn.running_mean→eco_3d.res_3d_5.res5b_bn.running_mean\n",
      "module.base_model.res5b_bn.running_var→eco_3d.res_3d_5.res5b_bn.running_var\n",
      "module.base_model.res5b_bn.num_batches_tracked→eco_3d.res_3d_5.res5b_bn.num_batches_tracked\n",
      "module.new_fc.weight→fc_final.weight\n",
      "module.new_fc.bias→fc_final.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 모델을 로드하는 함수 정의\n",
    "def load_pretrained_ECO(model_dict, pretrained_model_dict):\n",
    "    '''ECO 학습된 모델을 로드하는 함수\n",
    "    이번에 구축한 ECO는 학습된 모델과 레이어 순서가 같지만 이름이 다름\n",
    "    '''\n",
    "\n",
    "    # 현재 네트워크 모델의 파라미터명\n",
    "    param_names = []  # 파라미터명을 저장해 나간다\n",
    "    for name, param in model_dict.items():\n",
    "        param_names.append(name)\n",
    "\n",
    "    # 현재 네트워크 정보를 복사하여 새로운 state_dict를 작성\n",
    "    new_state_dict = model_dict.copy()\n",
    "\n",
    "    # 새 state_dict에 학습된 값을 대입\n",
    "    print(\"학습된 파라미터를 로드합니다\")\n",
    "    for index, (key_name, value) in enumerate(pretrained_model_dict.items()):\n",
    "        name = param_names[index]  # 현재 네트워크에서 파라미터명을 취득\n",
    "        new_state_dict[name] = value  # 값을 넣는다\n",
    "\n",
    "        # 무엇에 로드된 것인지를 표시\n",
    "        print(str(key_name)+\"→\"+str(name))\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "# 학습된 모델을 로드\n",
    "net_model_ECO = \"./weights/ECO_Lite_rgb_model_Kinetics.pth.tar\"\n",
    "pretrained_model = torch.load(net_model_ECO, map_location='cpu')\n",
    "pretrained_model_dict = pretrained_model['state_dict']\n",
    "# (주석)\n",
    "# pth가 tar로 압축되는 것은, state_dict 이외의 정보도 함께 저장되어 있기 때문이다.\n",
    "# 따라서 읽어들일 때에는 사전형 변수로 되어 있으므로, ['state_dict']을 지정한다.\n",
    "\n",
    "# 현재 모델의 변수명 등을 취득\n",
    "model_dict = net.state_dict()\n",
    "\n",
    "# 학습된 모델의 state_dict을 취득\n",
    "new_state_dict = load_pretrained_ECO(model_dict, pretrained_model_dict)\n",
    "\n",
    "# 학습된 모델의 파라미터를 대입\n",
    "net.eval()  # ECO 네트워크를 추론 모드로\n",
    "net.load_state_dict(new_state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론(동영상 데이터의 클래스 분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 400])\n"
     ]
    }
   ],
   "source": [
    "# 추론\n",
    "net.eval()  # ECO 네트워크를 추론 도ㅡ로\n",
    "\n",
    "batch_iterator = iter(val_dataloader)  # 반복자로 변환\n",
    "imgs_transformeds, labels, label_ids, dir_path = next(\n",
    "    batch_iterator)  # 1번째 요소를 꺼낸다\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    outputs = net(imgs_transformeds)  # ECO로 추론\n",
    "\n",
    "print(outputs.shape)  # 출력 크기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일:  ./data/kinetics_videos/arm wrestling/C4lCVBZ3ux0_000028_000038\n",
      "예측 1위: arm wrestling\n",
      "예측 2위: headbutting\n",
      "예측 3위: stretching leg\n",
      "예측 4위: shaking hands\n",
      "예측 5위: tai chi\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과 상위 5개를 표시합니다\n",
    "def show_eco_inference_result(dir_path, outputs_input, id_label_dict, idx=0):\n",
    "    '''미니 배치의 각 데이터에 대해, 추론 결과의 상위를 출력하는 함수 정의'''\n",
    "    print(\"파일: \", dir_path[idx])  # 파일명\n",
    "\n",
    "    outputs = outputs_input.clone()  # 사본 작성\n",
    "\n",
    "    for i in range(5):\n",
    "        '''1~5위까지 표시'''\n",
    "        output = outputs[idx]\n",
    "        _, pred = torch.max(output, dim=0)  # 확률 최대치 라벨을 예측\n",
    "        class_idx = int(pred.numpy())  # 클래스 ID 출력\n",
    "        print(\"예측 {}위: {}\".format(i+1, id_label_dict[class_idx]))\n",
    "        outputs[idx][class_idx] = -1000  # 최대치였던 것을 없앰(작게 한다)\n",
    "\n",
    "\n",
    "# 예측 실시\n",
    "idx = 0\n",
    "show_eco_inference_result(dir_path, outputs, id_label_dict, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일:  ./data/kinetics_videos/bungee jumping/TUvSX0pYu4o_000002_000012\n",
      "예측 1위: bungee jumping\n",
      "예측 2위: trapezing\n",
      "예측 3위: abseiling\n",
      "예측 4위: swinging on something\n",
      "예측 5위: climbing a rope\n"
     ]
    }
   ],
   "source": [
    "# 예측 실시\n",
    "idx = 4\n",
    "show_eco_inference_result(dir_path, outputs, id_label_dict, idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "끝"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}