{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "7-6_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1PpwmcMJFRB",
        "colab_type": "text"
      },
      "source": [
        "# 7.6 Transformer 모델(분류 작업용) 구현\n",
        "\n",
        "- 클래스 분류의 Transformer 모델을 구현합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aSx2BwBJFRC",
        "colab_type": "text"
      },
      "source": [
        "※ 이 장의 파일은 Ubuntu 환경에서의 동작을 전제로 하고 있습니다. Windows와 같이 문자 코드가 다른 환경에서는 동작에 주의하십시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD2JfFFgJFRD",
        "colab_type": "text"
      },
      "source": [
        "# 7.6 학습 목표\n",
        "\n",
        "1.\tTransformer 모듈의 구성을 이해한다\n",
        "2.\tLSTM이나 RNN을 사용하지 않아도 CNN 기반의 Transformer로 자연어 처리가 가능한 이유를 이해한다\n",
        "3.\tTransformer를 구현할 수 있다\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IBOjXDeJFRE",
        "colab_type": "text"
      },
      "source": [
        "# 사전 준비\n",
        "도서의 지시에 따라, 이 장에서 사용하는 데이터를 준비합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1kMABqAJFRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torchtext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2wc_IbWJFRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup seeds\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAB9spQJJFRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Embedder(nn.Module):\n",
        "    '''id로 표시된 단어를 벡터로 변환합니다'''\n",
        "\n",
        "    def __init__(self, text_embedding_vectors):\n",
        "        super(Embedder, self).__init__()\n",
        "\n",
        "        self.embeddings = nn.Embedding.from_pretrained(\n",
        "            embeddings=text_embedding_vectors, freeze=True)\n",
        "        # freeze=True에 의해 역전파로 갱신되지 않고, 변하지 않습니다\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_vec = self.embeddings(x)\n",
        "\n",
        "        return x_vec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loHdRkRaJFRQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "c584d9db-3cfe-4ea3-b1cf-6f5cf1c684fa"
      },
      "source": [
        "# 동작 확인\n",
        "\n",
        "# 이전 절의 DataLoader 등을 취득\n",
        "from utils.dataloader import get_IMDb_DataLoaders_and_TEXT\n",
        "train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(\n",
        "    max_length=256, batch_size=24)\n",
        "\n",
        "# 미니 비치 준비\n",
        "batch = next(iter(train_dl))\n",
        "\n",
        "# 모델 구축\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "\n",
        "# 입출력\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 단어를 벡터로\n",
        "\n",
        "print(\"입력 텐서 크기: \", x.shape)\n",
        "print(\"출력 텐서 크기: \", x1.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 텐서 크기:  torch.Size([24, 256])\n",
            "출력 텐서 크기:  torch.Size([24, 256, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-R3xrLWJFRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    '''입력된 단어의 위치를 나타내는 벡터 정보를 부가'''\n",
        "\n",
        "    def __init__(self, d_model=300, max_seq_len=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model  # 단어 벡터의 차원수\n",
        "\n",
        "        # 단어 순서(pos)와 내장 벡터의 차원 위치(i)에 의해 고유하게 정해지는 값의 표를 pe로 작성\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        # GPU가 사용 가능하면 GPU에 전달하는 것은, 여기서는 생략합니다. 실제 학습시에 사용합니다\n",
        "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # pe = pe.to(device)\n",
        "\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                \n",
        "                # 오탈자 수정_200510 #79\n",
        "                # pe[pos, i + 1] = math.cos(pos /\n",
        "                #                          (10000 ** ((2 * (i + 1))/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos /\n",
        "                                          (10000 ** ((2 * i)/d_model)))\n",
        "\n",
        "        # 표 pe의 선두에서, 미니 배치 차원을 더함\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "        # 경사를 계산하지 않음\n",
        "        self.pe.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # 입력 x와 Positonal Encoding을 더함\n",
        "        # x가 pe보다 작으므로 크게 한다\n",
        "        ret = math.sqrt(self.d_model)*x + self.pe\n",
        "        return ret\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZoqYmiiJFRX",
        "colab_type": "code",
        "colab": {},
        "outputId": "6f3815a2-2a4a-4bf6-bad9-0ccc6fe69821"
      },
      "source": [
        "# 동작 확인\n",
        "\n",
        "# 모델 구축\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "\n",
        "# 입출력\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 단어를 벡터로\n",
        "x2 = net2(x1)\n",
        "\n",
        "print(\"입력 텐서 크기: \", x1.shape)\n",
        "print(\"출력 텐서 크기: \", x2.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 텐서 크기:  torch.Size([24, 256, 300])\n",
            "출력 텐서 크기:  torch.Size([24, 256, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8wcSoeDJFRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    '''Transformer는 사실상 멀티 헤드 Attention이지만, \n",
        "    쉽게 이해되도록 우선 싱글 Attention로 구현합니다'''\n",
        "\n",
        "    def __init__(self, d_model=300):\n",
        "        super().__init__()\n",
        "\n",
        "        # SAGAN에서는 1dConv를 사용했지만, 이번에는 전결합층에서 특징량을 변환\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # 출력 시에 사용할 전결합층\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # Attention의 크기 조정 변수\n",
        "        self.d_k = d_model\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        # 전결합층에서 특징량을 변환\n",
        "        k = self.k_linear(k)\n",
        "        q = self.q_linear(q)\n",
        "        v = self.v_linear(v)\n",
        "\n",
        "        # Attention 값을 계산한다\n",
        "        # 각 값을 덧셈하면 너무 커지므로 root(d_k)로 나누어 조절\n",
        "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # 여기서 mask를 계산\n",
        "        mask = mask.unsqueeze(1)\n",
        "        weights = weights.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # softmax로 규격화\n",
        "        normlized_weights = F.softmax(weights, dim=-1)\n",
        "\n",
        "        # Attention을 Value와 곱하기\n",
        "        output = torch.matmul(normlized_weights, v)\n",
        "\n",
        "        # 전결합층에서 특징량을 변환\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, normlized_weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1AcDAfjJFRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
        "        '''Attention 층에서 출력을 단순히 전결합층 두 개로 특징량을 변환하는 유닛입니다'''\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.dropout(F.relu(x))\n",
        "        x = self.linear_2(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ5Y2sDDJFRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # LayerNormalization층\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Attention층\n",
        "        self.attn = Attention(d_model)\n",
        "\n",
        "        # Attention 다음의 전결합층 두 개\n",
        "        self.ff = FeedForward(d_model)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # 정규화와 Attention\n",
        "        x_normlized = self.norm_1(x)\n",
        "        output, normlized_weights = self.attn(\n",
        "            x_normlized, x_normlized, x_normlized, mask)\n",
        "        \n",
        "        x2 = x + self.dropout_1(output)\n",
        "\n",
        "        # 정규화와 전결합층\n",
        "        x_normlized2 = self.norm_2(x2)\n",
        "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
        "\n",
        "        return output, normlized_weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNaVWuNJJFRk",
        "colab_type": "code",
        "colab": {},
        "outputId": "e20710fc-c547-48e0-831d-3aef9d53c367"
      },
      "source": [
        "# 동작 확인\n",
        "\n",
        "# 모델 구축\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "net3 = TransformerBlock(d_model=300)\n",
        "\n",
        "# mask 작성\n",
        "x = batch.Text[0]\n",
        "input_pad = 1  # 단어 ID에 있어서, '<pad>': 1이므로\n",
        "input_mask = (x != input_pad)\n",
        "print(input_mask[0])\n",
        "\n",
        "# 입출력\n",
        "x1 = net1(x)  # 단어를 벡터로\n",
        "x2 = net2(x1)  # Positon 정보를 더한다\n",
        "x3, normlized_weights = net3(x2, input_mask)  # Self-Attention으로 특징량을 변환\n",
        "\n",
        "print(\"입력 텐서 크기: \", x2.shape)\n",
        "print(\"출력 텐서 크기: \", x3.shape)\n",
        "print(\"Attention 크기: \", normlized_weights.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.uint8)\n",
            "입력 텐서 크기:  torch.Size([24, 256, 300])\n",
            "출력 텐서 크기:  torch.Size([24, 256, 300])\n",
            "Attention 크기:  torch.Size([24, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcrNM1rpJFRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    '''Transformer_Block의 출력을 사용하여, 마지막에 클래스 분류를 시킨다'''\n",
        "\n",
        "    def __init__(self, d_model=300, output_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # 전결합층\n",
        "        self.linear = nn.Linear(d_model, output_dim)  # output_dim은 음성, 양성의 두 가지\n",
        "\n",
        "        # 가중치 초기화\n",
        "        nn.init.normal_(self.linear.weight, std=0.02)\n",
        "        nn.init.normal_(self.linear.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = x[:, 0, :]  # 각 미니 배치의 각 문장의 선두 단어의 특징량(300차원)을 꺼낸다\n",
        "        out = self.linear(x0)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUVS-wxoJFRq",
        "colab_type": "code",
        "colab": {},
        "outputId": "e52ae2a8-1e44-45ef-d00e-0ae01b4f1ad5"
      },
      "source": [
        "# 동작 확인\n",
        "\n",
        "# 미니 배치 준비\n",
        "batch = next(iter(train_dl))\n",
        "\n",
        "# 모델 구축\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "net3 = TransformerBlock(d_model=300)\n",
        "net4 = ClassificationHead(output_dim=2, d_model=300)\n",
        "\n",
        "# 입출력\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 단어를 벡터로\n",
        "x2 = net2(x1)  # Positon 정보를 더한다\n",
        "x3, normlized_weights = net3(x2, input_mask)  # Self-Attention으로 특징량을 변환\n",
        "x4 = net4(x3)  # 최종 출력의 0번째 단어를 사용하여, 분류0~1의 스칼라를 출력\n",
        "\n",
        "print(\"입력 텐서 사이즈: \", x3.shape)\n",
        "print(\"출력 텐서 사이즈: \", x4.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 텐서 사이즈:  torch.Size([24, 256, 300])\n",
            "출력 텐서 사이즈:  torch.Size([24, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8-NHGc3JFRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 최종적인 Transformer 모델의 클래스\n",
        "class TransformerClassification(nn.Module):\n",
        "    '''Transformer로 클래스 분류'''\n",
        "\n",
        "    def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256, output_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # 모델 구축\n",
        "        self.net1 = Embedder(text_embedding_vectors)\n",
        "        self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
        "        self.net3_1 = TransformerBlock(d_model=d_model)\n",
        "        self.net3_2 = TransformerBlock(d_model=d_model)\n",
        "        self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x1 = self.net1(x)  # 단어를 벡터로\n",
        "        x2 = self.net2(x1)  # Positon 정보를 더한다\n",
        "        x3_1, normlized_weights_1 = self.net3_1(\n",
        "            x2, mask)  # Self-Attention으로 특징량을 변환\n",
        "        x3_2, normlized_weights_2 = self.net3_2(\n",
        "            x3_1, mask)  # Self-Attention으로 특징량을 변환\n",
        "        x4 = self.net4(x3_2)  # 최종 출력의 0번째 단어를 사용하여, 분류0~1의 스칼라를 출력\n",
        "        return x4, normlized_weights_1, normlized_weights_2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2dt7_rvJFRv",
        "colab_type": "code",
        "colab": {},
        "outputId": "9b5659f4-2d7c-4a7d-e3ae-f2c1b0703750"
      },
      "source": [
        "# 동작 확인\n",
        "\n",
        "# 미니 배치 준비\n",
        "batch = next(iter(train_dl))\n",
        "\n",
        "# 모델 구축\n",
        "net = TransformerClassification(\n",
        "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)\n",
        "\n",
        "# 입출력\n",
        "x = batch.Text[0]\n",
        "input_mask = (x != input_pad)\n",
        "out, normlized_weights_1, normlized_weights_2 = net(x, input_mask)\n",
        "\n",
        "print(\"출력 텐서 크기: \", out.shape)\n",
        "print(\"출력 텐서의 sigmoid: \", F.softmax(out, dim=1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "출력 텐서 크기:  torch.Size([24, 2])\n",
            "출력 텐서의 sigmoid:  tensor([[0.6980, 0.3020],\n",
            "        [0.7318, 0.2682],\n",
            "        [0.7244, 0.2756],\n",
            "        [0.7135, 0.2865],\n",
            "        [0.7022, 0.2978],\n",
            "        [0.6974, 0.3026],\n",
            "        [0.6831, 0.3169],\n",
            "        [0.6487, 0.3513],\n",
            "        [0.7096, 0.2904],\n",
            "        [0.7221, 0.2779],\n",
            "        [0.7213, 0.2787],\n",
            "        [0.7046, 0.2954],\n",
            "        [0.6738, 0.3262],\n",
            "        [0.7069, 0.2931],\n",
            "        [0.7217, 0.2783],\n",
            "        [0.6837, 0.3163],\n",
            "        [0.7011, 0.2989],\n",
            "        [0.6944, 0.3056],\n",
            "        [0.6860, 0.3140],\n",
            "        [0.7183, 0.2817],\n",
            "        [0.7256, 0.2744],\n",
            "        [0.7288, 0.2712],\n",
            "        [0.6678, 0.3322],\n",
            "        [0.7253, 0.2747]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSSYMFxdJFRx",
        "colab_type": "text"
      },
      "source": [
        "지금까지의 내용을 \"utils\" 폴더의 transformer.py에 별도로 저장해 두고, 다음 절에서는 해당 파일을 읽어 사용합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLLg9VGIJFRx",
        "colab_type": "text"
      },
      "source": [
        "끝"
      ]
    }
  ]
}