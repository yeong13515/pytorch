{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 torchtext에서의 Dataset, DataLoader 구현 방법\n",
    "\n",
    "- torchtext를 사용하여 Dataset 및 DataLoader을 구현하는 방법을 설명합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※　이 장의 파일은 Ubuntu 환경에서의 동작을 전제로 하고 있습니다. Windows와 같이 문자 코드가 다른 환경에서는 동작에 주의하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 학습 목표\n",
    "\n",
    "1.\ttorchtext를 이용하여 Dataset 및 DataLoader를 구현할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전 준비\n",
    "\n",
    "- 도서의 지시에 따라, 이 장에서 사용하는 데이터를 준비합니다\n",
    "\n",
    "- torchtext를 설치합니다\n",
    "\n",
    "- pip install torchtext\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 . 전처리 및 단어 분할 함수 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 분할에는 Janome을 사용\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "j_t = Tokenizer()\n",
    "\n",
    "\n",
    "def tokenizer_janome(text):\n",
    "    return [tok for tok in j_t.tokenize(text, wakati=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리로서, 정규화 함수를 정의\n",
    "import re\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    # 반각 및 전각의 통일\n",
    "    # 이번에는 무시\n",
    "\n",
    "    # 영어의 소문자화\n",
    "    # 이번에는 무시\n",
    "    # output = output.lower()\n",
    "\n",
    "    # 줄 바꿈, 반각 스페이스, 전각 스페이스를 삭제\n",
    "    text = re.sub('\\r', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('　', '', text)\n",
    "    text = re.sub(' ', '', text)\n",
    "\n",
    "    # 숫자를 일률적으로 \"0\"로 설정\n",
    "    text = re.sub(r'[0-9 ０-９]', '0', text)  # 숫자\n",
    "\n",
    "    # 기호와 숫자 제거\n",
    "    # 이번에는 무시. 반각 기호, 숫자, 영자(英字)\n",
    "    # 이번에는 무시. 전각 기호\n",
    "\n",
    "    # 특정 문자를 정규 표현으로 치환\n",
    "    # 이번에는 무시\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['昨日', 'は', 'とても', '暑く', ', ', '気温', 'が', '00', '度', 'も', 'あっ', 'た', '。']\n"
     ]
    }
   ],
   "source": [
    "# 전처리 및 Janome의 단어 분할을 수행하는 함수를 정의한다\n",
    "def tokenizer_with_preprocessing(text):\n",
    "    text = preprocessing_text(text)  # 전처리 정규화\n",
    "    ret = tokenizer_janome(text)  # Janome 단어 분할\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "# 동작 확인\n",
    "text = \"昨日は とても暑く, 気温が36度もあった。\"\n",
    "print(tokenizer_with_preprocessing(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 문장 데이터 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "\n",
    "# tsv나 csv 데이터를 읽을 때, 읽어들인 내용에 대해 수행할 처리를 정의합니다\n",
    "# 문장과 라벨을 모두 준비합니다\n",
    "\n",
    "max_length = 25\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing,\n",
    "                            use_vocab=True, lower=True, include_lengths=True, batch_first=True, fix_length=max_length)\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "# 인수의 의미는 다음과 같습니다\n",
    "# sequential: 데이터의 길이가 가변인가? 문장은 길이가 다양하므로 True. 라벨은 False\n",
    "# tokenize: 문장을 읽을 때, 전처리 및 단어 분할 함수를 정의\n",
    "# use_vocab: 단어를 vocabulary(단어집: 이후에 설명)에 추가할지 여부\n",
    "# lower: 알파벳이 존재할 때 소문자로 변환할지 여부\n",
    "# include_length: 문장의 단어 수 데이터를 포함할지 여부\n",
    "# batch_first: 미니 배치 차원을 선두에 제공할지 여부\n",
    "# fix_length: 전체 문장을 지정한 길이가 되도록 padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 수 4\n",
      "첫번째 훈련 데이터 {'Text': ['王', 'と', '王子', 'と', '女王', 'と', '姫', 'と', '男性', 'と', '女性', 'が', 'い', 'まし', 'た', '。'], 'Label': '0'}\n",
      "두번째 훈련 데이터 {'Text': ['機械', '学習', 'が', '好き', 'です', '。'], 'Label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# data.TabularDataset의 상세 정보\n",
    "# https://torchtext.readthedocs.io/en/latest/examples.html?highlight=data.TabularDataset.splits\n",
    "\n",
    "# \"data\" 폴더에서 각 tsv 파일을 읽어들여, Dataset으로 합니다\n",
    "# 1행이 TEXT와 LABEL로 구분되었음을 fields에서 지시합니다\n",
    "train_ds, val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
    "    path='./data/', train='text_train.tsv',\n",
    "    validation='text_val.tsv', test='text_test.tsv', format='tsv',\n",
    "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
    "\n",
    "\n",
    "# 동작 확인\n",
    "print('훈련 데이터 수', len(train_ds))\n",
    "print('첫번째 훈련 데이터', vars(train_ds[0]))\n",
    "print('두번째 훈련 데이터', vars(train_ds[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어의 수치화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'王': 1,\n",
       "         'と': 5,\n",
       "         '王子': 1,\n",
       "         '女王': 1,\n",
       "         '姫': 1,\n",
       "         '男性': 1,\n",
       "         '女性': 1,\n",
       "         'が': 3,\n",
       "         'い': 1,\n",
       "         'まし': 1,\n",
       "         'た': 1,\n",
       "         '。': 4,\n",
       "         '機械': 1,\n",
       "         '学習': 1,\n",
       "         '好き': 1,\n",
       "         'です': 1,\n",
       "         '本章': 2,\n",
       "         'から': 1,\n",
       "         '自然': 1,\n",
       "         '言語': 1,\n",
       "         '処理': 1,\n",
       "         'に': 1,\n",
       "         '取り組み': 1,\n",
       "         'ます': 2,\n",
       "         'で': 1,\n",
       "         'は': 1,\n",
       "         '商品': 1,\n",
       "         'レビュー': 1,\n",
       "         'の': 4,\n",
       "         '短い': 1,\n",
       "         '文章': 4,\n",
       "         'に対して': 1,\n",
       "         ', ': 3,\n",
       "         'その': 1,\n",
       "         'negative': 1,\n",
       "         'な': 4,\n",
       "         '評価': 2,\n",
       "         'を': 3,\n",
       "         'し': 3,\n",
       "         'て': 2,\n",
       "         'いる': 2,\n",
       "         'か': 2,\n",
       "         'positive': 1,\n",
       "         '0': 1,\n",
       "         '値': 1,\n",
       "         'クラス': 1,\n",
       "         '分類': 2,\n",
       "         'する': 1,\n",
       "         'モデル': 1,\n",
       "         '構築': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary를 작성합니다\n",
    "# 훈련 데이터 train의 단어에서 min_freq 이상의 빈도 단어를 사용하여 vocabulary(단어집)를 구축\n",
    "TEXT.build_vocab(train_ds, min_freq=1)\n",
    "\n",
    "# 훈련 데이터의 단어와 빈도를 출력(빈도 min_freq보다 큰 것이 출력됩니다)\n",
    "TEXT.vocab.freqs  # 출력하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index()>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             'と': 2,\n",
       "             '。': 3,\n",
       "             'な': 4,\n",
       "             'の': 5,\n",
       "             '文章': 6,\n",
       "             ', ': 7,\n",
       "             'が': 8,\n",
       "             'し': 9,\n",
       "             'を': 10,\n",
       "             'いる': 11,\n",
       "             'か': 12,\n",
       "             'て': 13,\n",
       "             'ます': 14,\n",
       "             '分類': 15,\n",
       "             '本章': 16,\n",
       "             '評価': 17,\n",
       "             '0': 18,\n",
       "             'い': 19,\n",
       "             'から': 20,\n",
       "             'する': 21,\n",
       "             'その': 22,\n",
       "             'た': 23,\n",
       "             'で': 24,\n",
       "             'です': 25,\n",
       "             'に': 26,\n",
       "             'に対して': 27,\n",
       "             'は': 28,\n",
       "             'まし': 29,\n",
       "             'クラス': 30,\n",
       "             'negative': 31,\n",
       "             'positive': 32,\n",
       "             'モデル': 33,\n",
       "             'レビュー': 34,\n",
       "             '値': 35,\n",
       "             '処理': 36,\n",
       "             '取り組み': 37,\n",
       "             '商品': 38,\n",
       "             '女性': 39,\n",
       "             '女王': 40,\n",
       "             '好き': 41,\n",
       "             '姫': 42,\n",
       "             '学習': 43,\n",
       "             '構築': 44,\n",
       "             '機械': 45,\n",
       "             '王': 46,\n",
       "             '王子': 47,\n",
       "             '男性': 48,\n",
       "             '短い': 49,\n",
       "             '自然': 50,\n",
       "             '言語': 51})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary의 단어를 id로 변환한 결과를 출력.\n",
    "# 빈도가 min_freq보다 작은 경우에는 알 수 없음<unk>이 된다\n",
    "\n",
    "TEXT.vocab.stoi  # 출력. string to identifiers 문자열을 id로\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[46,  2, 47,  2, 40,  2, 42,  2, 48,  2, 39,  8, 19, 29, 23,  3,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1],\n",
      "        [45, 43,  8, 41, 25,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1]]), tensor([16,  6]))\n",
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader를 작성합니다(torchtext의 맥락에서는 단순히 iterater로 부릅니다)\n",
    "train_dl = torchtext.data.Iterator(train_ds, batch_size=2, train=True)\n",
    "\n",
    "val_dl = torchtext.data.Iterator(\n",
    "    val_ds, batch_size=2, train=False, sort=False)\n",
    "\n",
    "test_dl = torchtext.data.Iterator(\n",
    "    test_ds, batch_size=2, train=False, sort=False)\n",
    "\n",
    "\n",
    "# 동작 확인 - 검증 데이터의 데이터 세트로 확인\n",
    "batch = next(iter(val_dl))\n",
    "print(batch.Text)\n",
    "print(batch.Label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "끝"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}